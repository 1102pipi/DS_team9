[09:19:11,154][WARNING][main][G] Ignite work directory is not provided, automatically resolved to: C:\Users\pipi\OneDrive\桌面\apache-ignite-2.16.0-bin\work
[09:19:11,353][INFO][main][IgniteKernal] 

>>>    __________  ________________  
>>>   /  _/ ___/ |/ /  _/_  __/ __/  
>>>  _/ // (7 7    // /  / / / _/    
>>> /___/\___/_/|_/___/ /_/ /___/   
>>> 
>>> ver. 2.16.0#20231215-sha1:7bde6a42
>>> 2023 Copyright(C) Apache Software Foundation
>>> 
>>> Ignite documentation: https://ignite.apache.org

[09:19:11,360][INFO][main][IgniteKernal] Config URL: file:/C:/Users/pipi/OneDrive/桌面/apache-ignite-2.16.0-bin/config/default-config.xml
[09:19:11,371][INFO][main][IgniteKernal] IgniteConfiguration [igniteInstanceName=null, pubPoolSize=16, svcPoolSize=16, callbackPoolSize=16, stripedPoolSize=16, sysPoolSize=16, mgmtPoolSize=4, dataStreamerPoolSize=16, utilityCachePoolSize=16, utilityCacheKeepAliveTime=60000, p2pPoolSize=2, qryPoolSize=16, buildIdxPoolSize=4, igniteHome=C:\Users\pipi\OneDrive\桌面\apache-ignite-2.16.0-bin, igniteWorkDir=C:\Users\pipi\OneDrive\桌面\apache-ignite-2.16.0-bin\work, mbeanSrv=com.sun.jmx.mbeanserver.JmxMBeanServer@68f4865, nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, marsh=BinaryMarshaller [], marshLocJobs=false, p2pEnabled=false, netTimeout=5000, netCompressionLevel=1, sndRetryDelay=1000, sndRetryCnt=3, metricsHistSize=10000, metricsUpdateFreq=2000, metricsExpTime=9223372036854775807, discoSpi=TcpDiscoverySpi [addrRslvr=null, addressFilter=null, sockTimeout=0, ackTimeout=0, marsh=null, reconCnt=10, reconDelay=2000, maxAckTimeout=600000, soLinger=0, forceSrvMode=false, clientReconnectDisabled=false, internalLsnr=null, skipAddrsRandomization=false], segPlc=USE_FAILURE_HANDLER, segResolveAttempts=2, waitForSegOnStart=true, allResolversPassReq=true, segChkFreq=10000, commSpi=TcpCommunicationSpi [connectGate=org.apache.ignite.spi.communication.tcp.internal.ConnectGateway@cb191ca, ctxInitLatch=java.util.concurrent.CountDownLatch@42f48531[Count = 1], stopping=false, clientPool=null, nioSrvWrapper=null, stateProvider=null], evtSpi=org.apache.ignite.spi.eventstorage.NoopEventStorageSpi@a776e, colSpi=NoopCollisionSpi [], deploySpi=LocalDeploymentSpi [], indexingSpi=org.apache.ignite.spi.indexing.noop.NoopIndexingSpi@19ae6bb, addrRslvr=null, encryptionSpi=org.apache.ignite.spi.encryption.noop.NoopEncryptionSpi@10993713, tracingSpi=org.apache.ignite.spi.tracing.NoopTracingSpi@58359ebd, clientMode=false, rebalanceThreadPoolSize=4, rebalanceTimeout=10000, rebalanceBatchesPrefetchCnt=3, rebalanceThrottle=0, rebalanceBatchSize=524288, txCfg=TransactionConfiguration [txSerEnabled=false, dfltIsolation=REPEATABLE_READ, dfltConcurrency=PESSIMISTIC, dfltTxTimeout=0, txTimeoutOnPartitionMapExchange=0, pessimisticTxLogSize=0, pessimisticTxLogLinger=10000, tmLookupClsName=null, txManagerFactory=null, useJtaSync=false], cacheSanityCheckEnabled=true, discoStartupDelay=60000, deployMode=SHARED, p2pMissedCacheSize=100, locHost=null, timeSrvPortBase=31100, timeSrvPortRange=100, failureDetectionTimeout=10000, sysWorkerBlockedTimeout=null, clientFailureDetectionTimeout=30000, metricsLogFreq=60000, connectorCfg=ConnectorConfiguration [jettyPath=null, host=null, port=11211, noDelay=true, directBuf=false, sndBufSize=32768, rcvBufSize=32768, idleQryCurTimeout=600000, idleQryCurCheckFreq=60000, sndQueueLimit=0, selectorCnt=4, idleTimeout=7000, sslEnabled=false, sslClientAuth=false, sslFactory=null, portRange=100, threadPoolSize=16, msgInterceptor=null], odbcCfg=null, warmupClos=null, atomicCfg=AtomicConfiguration [seqReserveSize=1000, cacheMode=PARTITIONED, backups=1, aff=null, grpName=null], classLdr=null, sslCtxFactory=null, platformCfg=null, binaryCfg=null, memCfg=null, pstCfg=null, dsCfg=DataStorageConfiguration [pageSize=0, concLvl=0, sysDataRegConf=org.apache.ignite.configuration.SystemDataRegionConfiguration@4b672daa, dfltDataRegConf=DataRegionConfiguration [name=default, maxSize=3396068147, initSize=268435456, swapPath=null, pageEvictionMode=DISABLED, pageReplacementMode=CLOCK, evictionThreshold=0.9, emptyPagesPoolSize=100, metricsEnabled=false, metricsSubIntervalCount=5, metricsRateTimeInterval=60000, persistenceEnabled=false, checkpointPageBufSize=0, lazyMemoryAllocation=true, warmUpCfg=null, memoryAllocator=null, cdcEnabled=false], dataRegions=null, storagePath=null, checkpointFreq=180000, lockWaitTime=10000, checkpointThreads=4, checkpointWriteOrder=SEQUENTIAL, walHistSize=20, maxWalArchiveSize=1073741824, walSegments=10, walSegmentSize=67108864, walPath=db/wal, walArchivePath=db/wal/archive, cdcWalPath=db/wal/cdc, cdcWalDirMaxSize=0, metricsEnabled=false, walMode=LOG_ONLY, walTlbSize=131072, walBuffSize=0, walFlushFreq=2000, walFsyncDelay=1000, walRecordIterBuffSize=67108864, alwaysWriteFullPages=false, fileIOFactory=org.apache.ignite.internal.processors.cache.persistence.file.AsyncFileIOFactory@2e11485, metricsSubIntervalCnt=5, metricsRateTimeInterval=60000, walAutoArchiveAfterInactivity=-1, walForceArchiveTimeout=-1, writeThrottlingEnabled=false, walCompactionEnabled=false, walCompactionLevel=1, checkpointReadLockTimeout=null, walPageCompression=DISABLED, walPageCompressionLevel=null, dfltWarmUpCfg=null, encCfg=org.apache.ignite.configuration.EncryptionConfiguration@662f5666, defragmentationThreadPoolSize=4, minWalArchiveSize=-1, memoryAllocator=null], snapshotPath=snapshots, snapshotThreadPoolSize=4, activeOnStart=true, activeOnStartPropSetFlag=false, autoActivation=true, autoActivationPropSetFlag=false, clusterStateOnStart=null, sqlConnCfg=null, cliConnCfg=ClientConnectorConfiguration [host=null, port=10800, portRange=100, sockSndBufSize=0, sockRcvBufSize=0, tcpNoDelay=true, maxOpenCursorsPerConn=128, threadPoolSize=16, selectorCnt=8, idleTimeout=0, handshakeTimeout=10000, jdbcEnabled=true, odbcEnabled=true, thinCliEnabled=true, sslEnabled=false, useIgniteSslCtxFactory=true, sslClientAuth=false, sslCtxFactory=null, thinCliCfg=ThinClientConfiguration [maxActiveTxPerConn=100, maxActiveComputeTasksPerConn=0, sendServerExcStackTraceToClient=false], sesOutboundMsgQueueLimit=0], mvccVacuumThreadCnt=2, mvccVacuumFreq=5000, authEnabled=false, failureHnd=null, commFailureRslvr=null, sqlCfg=SqlConfiguration [longQryWarnTimeout=3000, dfltQryTimeout=0, sqlQryHistSize=1000, validationEnabled=false], asyncContinuationExecutor=null]
[09:19:11,372][INFO][main][IgniteKernal] OS: Windows 11 10.0 amd64
[09:19:11,372][INFO][main][IgniteKernal] OS user: pipi
[09:19:11,381][INFO][main][IgniteKernal] PID: 7588
[09:19:11,382][INFO][main][IgniteKernal] Language runtime: Java Platform API Specification ver. 22
[09:19:11,382][INFO][main][IgniteKernal] VM information: Java(TM) SE Runtime Environment 22.0.1+8-16 Oracle Corporation Java HotSpot(TM) 64-Bit Server VM 22.0.1+8-16
[09:19:11,382][INFO][main][IgniteKernal] VM total memory: 1.0GB
[09:19:11,382][INFO][main][IgniteKernal] Remote Management [restart: on, REST: on, JMX (remote: off)]
[09:19:11,382][INFO][main][IgniteKernal] Logger: JavaLogger [quiet=true, config=null]
[09:19:11,382][INFO][main][IgniteKernal] IGNITE_HOME=C:\Users\pipi\OneDrive\桌面\apache-ignite-2.16.0-bin
[09:19:11,382][INFO][main][IgniteKernal] VM arguments: [--add-opens=java.base/jdk.internal.access=ALL-UNNAMED, --add-opens=java.base/jdk.internal.misc=ALL-UNNAMED, --add-opens=java.base/sun.nio.ch=ALL-UNNAMED, --add-opens=java.base/sun.util.calendar=ALL-UNNAMED, --add-opens=java.management/com.sun.jmx.mbeanserver=ALL-UNNAMED, --add-opens=jdk.internal.jvmstat/sun.jvmstat.monitor=ALL-UNNAMED, --add-opens=java.base/sun.reflect.generics.reflectiveObjects=ALL-UNNAMED, --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED, --add-opens=java.base/java.io=ALL-UNNAMED, --add-opens=java.base/java.nio=ALL-UNNAMED, --add-opens=java.base/java.net=ALL-UNNAMED, --add-opens=java.base/java.util=ALL-UNNAMED, --add-opens=java.base/java.util.concurrent=ALL-UNNAMED, --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED, --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED, --add-opens=java.base/java.lang=ALL-UNNAMED, --add-opens=java.base/java.lang.invoke=ALL-UNNAMED, --add-opens=java.base/java.math=ALL-UNNAMED, --add-opens=java.sql/java.sql=ALL-UNNAMED, --add-opens=java.base/java.lang.reflect=ALL-UNNAMED, --add-opens=java.base/java.time=ALL-UNNAMED, --add-opens=java.base/java.text=ALL-UNNAMED, --add-opens=java.management/sun.management=ALL-UNNAMED, --add-opens=java.desktop/java.awt.font=ALL-UNNAMED, -Xms1g, -Xmx1g, -XX:MaxMetaspaceSize=256m, -DIGNITE_QUIET=true, -DIGNITE_SUCCESS_FILE=C:\Users\pipi\OneDrive\桌面\apache-ignite-2.16.0-bin\work\ignite_success_1c3f674a-5559-49cf-b24e-ffbcd3fa164a, -DIGNITE_HOME=C:\Users\pipi\OneDrive\桌面\apache-ignite-2.16.0-bin, -DIGNITE_PROG_NAME=ignite.bat, -Dfile.encoding=UTF-8]
[09:19:11,382][INFO][main][IgniteKernal] System cache's DataRegion size is configured to 40 MB. Use DataStorageConfiguration.systemRegionInitialSize property to change the setting.
[09:19:11,382][INFO][main][IgniteKernal] Configured caches [in 'sysMemPlc' dataRegion: ['ignite-sys-cache'], in 'default' dataRegion: ['my_cache']]
[09:19:11,382][WARNING][main][IgniteKernal] Please set system property '-Djava.net.preferIPv4Stack=true' to avoid possible problems in mixed environments.
[09:19:11,382][INFO][main][IgniteKernal] 3-rd party licenses can be found at: C:\Users\pipi\OneDrive\桌面\apache-ignite-2.16.0-bin\libs\licenses
[09:19:11,442][INFO][main][IgnitePluginProcessor] Configured plugins:
[09:19:11,442][INFO][main][IgnitePluginProcessor]   ^-- None
[09:19:11,442][INFO][main][IgnitePluginProcessor] 
[09:19:11,444][INFO][main][FailureProcessor] Configured failure handler: [hnd=StopNodeOrHaltFailureHandler [tryStop=false, timeout=0, super=AbstractFailureHandler [ignoredFailureTypes=UnmodifiableSet [SYSTEM_WORKER_BLOCKED, SYSTEM_CRITICAL_OPERATION_TIMEOUT]]]]
[09:19:11,697][INFO][main][TcpCommunicationSpi] Successfully bound communication NIO server to TCP port [port=47100, locHost=0.0.0.0/0.0.0.0, selectorsCnt=8, selectorSpins=0, pairedConn=false]
[09:19:11,697][WARNING][main][TcpCommunicationSpi] Message queue limit is set to 0 which may lead to potential OOMEs when running cache operations in FULL_ASYNC or PRIMARY_SYNC modes due to message queues growth on sender and receiver sides.
[09:19:11,726][INFO][main][GridCollisionManager] Collision resolution is disabled (all jobs will be activated upon arrival).
[09:19:11,906][INFO][main][TcpDiscoverySpi] Successfully bound to TCP port [port=47500, localHost=0.0.0.0/0.0.0.0, locNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:19:11,907][INFO][main][GridLocalConfigManager] Resolved page store work directory: C:\Users\pipi\OneDrive\桌面\apache-ignite-2.16.0-bin\work\db\0_0_0_0_0_0_0_1_127_0_0_1_192_168_1_201_47500
[09:19:11,935][INFO][main][IgniteCacheDatabaseSharedManager] Configured data regions initialized successfully [total=4]
[09:19:12,011][WARNING][main][IgniteH2Indexing] Serialization of Java objects in H2 was enabled.
[09:19:12,156][INFO][main][ClientListenerProcessor] Client connector processor has started on TCP port 10800
[09:19:12,194][INFO][main][GridTcpRestProtocol] Command protocol successfully started [name=TCP binary, host=0.0.0.0/0.0.0.0, port=11211]
[09:19:12,242][INFO][main][IgniteKernal] Non-loopback local IPs: 192.168.1.201, fe80:0:0:0:50aa:704c:dc86:cc97%ethernet_32769, fe80:0:0:0:d28d:5091:418f:8ea7%wireless_32769, fe80:0:0:0:dd5a:4392:a3e4:5907%wireless_32768, fe80:0:0:0:de3e:31df:6220:8ab5%ethernet_32770, fe80:0:0:0:fbb0:611b:a364:8ccc%wireless_32770
[09:19:12,242][INFO][main][IgniteKernal] Enabled local MACs: 0433C2F50C17, 0433C2F50C18, 0433C2F50C1B, 0633C2F50C17, 2CF05D64F75A
[09:19:12,246][INFO][main][ClusterProcessor] Cluster ID and tag has been read from metastorage: null
[09:19:12,249][INFO][main][IgniteClusterImpl] Shutdown policy was updated [oldVal=null, newVal=null]
[09:19:12,251][INFO][main][IgniteStatisticsManagerImpl] Statistics usage state was changed from null to null
[09:19:12,262][WARNING][main][TcpDiscoveryMulticastIpFinder] TcpDiscoveryMulticastIpFinder has no pre-configured addresses (it is recommended in production to specify at least one address in TcpDiscoveryMulticastIpFinder.getAddresses() configuration property)
[09:19:13,866][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61492]
[09:19:13,879][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61492]
[09:19:13,880][INFO][tcp-disco-sock-reader-[]-#5-#72][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61492, rmtPort=61492]
[09:19:13,883][INFO][tcp-disco-sock-reader-[]-#5-#72][TcpDiscoverySpi] Received ping request from the remote node [rmtNodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, rmtAddr=/192.168.1.133:61492, rmtPort=61492]
[09:19:13,887][INFO][tcp-disco-sock-reader-[]-#5-#72][TcpDiscoverySpi] Finished writing ping response [rmtNodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, rmtAddr=/192.168.1.133:61492, rmtPort=61492]
[09:19:13,888][INFO][tcp-disco-sock-reader-[]-#5-#72][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61492, rmtPort=61492, rmtNodeId=null]
[09:19:13,934][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61493]
[09:19:13,935][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61493]
[09:19:13,936][INFO][tcp-disco-sock-reader-[]-#6-#73][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61493, rmtPort=61493]
[09:19:13,939][INFO][tcp-disco-sock-reader-[fcb17b28 192.168.1.133:61493]-#6-#73][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, rmtAddr=/192.168.1.133:61493]
[09:19:14,053][INFO][tcp-disco-msg-worker-[]-#2-#69][TcpDiscoverySpi] New next node [newNext=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=null, discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]]
[09:19:14,301][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][ClusterProcessor] Cluster tag will be set to new value: sweet_poincare, previous value was: null
[09:19:14,302][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][DistributedBaselineConfiguration] Baseline parameter 'baselineAutoAdjustEnabled' was changed from 'null' to 'true'
[09:19:14,303][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][DistributedBaselineConfiguration] Baseline parameter 'baselineAutoAdjustTimeout' was changed from 'null' to '0'
[09:19:14,304][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][IgniteTxManager] Transactions parameter 'longOperationsDumpTimeout' was changed from 'null' to '60000'
[09:19:14,306][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][IgniteTxManager] Transactions parameter 'longTransactionTimeDumpThreshold' was changed from 'null' to '0'
[09:19:14,307][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][IgniteTxManager] Transactions parameter 'transactionTimeDumpSamplesCoefficient' was changed from 'null' to '0.0'
[09:19:14,308][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][IgniteTxManager] Transactions parameter 'longTransactionTimeDumpSamplesPerSecondLimit' was changed from 'null' to '5'
[09:19:14,309][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][IgniteTxManager] Transactions parameter 'collisionsDumpInterval' was changed from 'null' to '1000'
[09:19:14,312][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][IgniteTxManager] Transactions parameter 'txOwnerDumpRequestsAllowed' was changed from 'null' to 'true'
[09:19:14,313][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][IgniteSnapshotManager] The snapshot transfer rate is not limited.
[09:19:14,314][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][IgniteH2Indexing] SQL parameter 'sql.defaultQueryTimeout' was changed from 'null' to '0'
[09:19:14,315][INFO][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][IgniteH2Indexing] SQL parameter 'sql.disabledFunctions' was changed from 'null' to '[FILE_WRITE, CANCEL_SESSION, MEMORY_USED, CSVREAD, LINK_SCHEMA, MEMORY_FREE, FILE_READ, CSVWRITE, SESSION_ID, LOCK_MODE]'
[09:19:14,325][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: a84ef531-529f-41b0-bf7b-ad5fd9d5feb1
[09:19:14,326][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:19:14,326][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:19:14,326][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:19:14,327][INFO][disco-notifier-worker-#68][MvccProcessorImpl] Assigned mvcc coordinator [crd=MvccCoordinator [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], nodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, ver=1717463896733, local=false, initialized=false]]
[09:19:14,335][INFO][sys-#76][ClusterProcessor] Writing cluster ID and tag to metastorage on ready for write ClusterIdAndTag [id=01b1afbe-15dc-4d29-9c1d-8d20efbc68e9, tag=sweet_poincare]
[09:19:14,456][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], crd=false, evt=NODE_JOINED, evtNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:19:14,465][INFO][exchange-worker-#77][IgniteCacheDatabaseSharedManager] Data Regions Started: 4
[09:19:14,467][INFO][exchange-worker-#77][msg] Components activation performed in 10 ms.
[09:19:14,526][INFO][exchange-worker-#77][GridCacheProcessor] Started cache [name=my_cache, id=-479252689, dataRegionName=default, mode=REPLICATED, atomicity=TRANSACTIONAL, backups=2147483647]
[09:19:14,526][INFO][sys-#82][GridCacheProcessor] Started cache [name=ignite-sys-cache, id=-2100569601, dataRegionName=sysMemPlc, mode=REPLICATED, atomicity=TRANSACTIONAL, backups=2147483647]
[09:19:14,538][INFO][exchange-worker-#77][GridCacheProcessor] Starting caches on local join performed in 79 ms.
[09:19:14,542][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Skipped waiting for partitions release future (local node is joining) [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0]]
[09:19:14,647][INFO][grid-nio-worker-tcp-comm-0-#39%TcpCommunicationSpi%][TcpCommunicationSpi] Established outgoing communication connection [locAddr=/192.168.1.201:63626, rmtAddr=/192.168.1.133:47100]
[09:19:14,649][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], crd=false]
[09:19:14,740][INFO][sys-#88][GridDhtPartitionsExchangeFuture] Received full message, will finish exchange [node=fcb17b28-510d-4c0b-b678-9eee64710d12, resVer=AffinityTopologyVersion [topVer=2, minorTopVer=0]]
[09:19:14,789][INFO][sys-#88][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], err=null, rebalanced=false, wasRebalanced=false]
[09:19:14,795][INFO][sys-#88][GridCacheProcessor] Finish proxy initialization, cacheName=my_cache, localNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1
[09:19:14,796][INFO][sys-#88][GridCacheProcessor] Finish proxy initialization, cacheName=ignite-sys-cache, localNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1
[09:19:14,796][INFO][sys-#88][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], evt=NODE_JOINED, evtNode=TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, addrs=ArrayList [0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], sockAddrs=HashSet [MSI/192.168.1.201:47500, /[0:0:0:0:0:0:0:1]:47500, /127.0.0.1:47500], discPort=47500, order=2, intOrder=2, lastExchangeTime=1717463954423, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=false, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0]]
[09:19:14,797][INFO][sys-#88][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], stage="Waiting in exchange queue" (124 ms), stage="Exchange parameters initialization" (1 ms), stage="Components activation" (10 ms), stage="Determine exchange type" (74 ms), stage="Preloading notification" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for Full message" (198 ms), stage="Affinity recalculation" (45 ms), stage="Full map updating" (2 ms), stage="Exchange done" (7 ms), stage="Total time" (461 ms)]
[09:19:14,797][INFO][sys-#88][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], stage="Affinity fetch" (73 ms) (parent=Determine exchange type), stage="Affinity initialization (local join) [grp=my_cache]" (45 ms) (parent=Affinity recalculation), stage="Affinity initialization (local join) [grp=ignite-sys-cache]" (26 ms) (parent=Affinity recalculation)]
[09:19:14,809][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Rebalancing scheduled [order=[ignite-sys-cache, my_cache], top=AffinityTopologyVersion [topVer=2, minorTopVer=0], rebalanceId=1, evt=NODE_JOINED, node=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:19:14,810][INFO][exchange-worker-#77][GridDhtPartitionDemander] Prepared rebalancing [grp=ignite-sys-cache, mode=SYNC, supplier=fcb17b28-510d-4c0b-b678-9eee64710d12, partitionsCount=100, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], rebalanceId=1]
[09:19:14,811][INFO][exchange-worker-#77][PartitionsEvictManager] Eviction in progress [groups=1, remainingPartsToEvict=0]
[09:19:14,811][INFO][exchange-worker-#77][PartitionsEvictManager] Group eviction in progress [grpName=ignite-sys-cache, grpId=-2100569601, remainingPartsToEvict=1, partsEvictInProgress=0, totalParts=100]
[09:19:14,813][INFO][exchange-worker-#77][PartitionsEvictManager] Partitions have been scheduled for eviction: [grpId=-2100569601, grpName=ignite-sys-cache, clearing=[0]]
[09:19:14,816][INFO][sys-#79][GridDhtPartitionDemander] Starting rebalance routine [ignite-sys-cache, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], supplier=fcb17b28-510d-4c0b-b678-9eee64710d12, fullPartitions=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99], histPartitions=[], rebalanceId=1]
[09:19:14,857][INFO][rebalance-#98][GridDhtPartitionDemander] Completed (final) rebalancing [rebalanceId=1, grp=ignite-sys-cache, supplier=fcb17b28-510d-4c0b-b678-9eee64710d12, partitions=100, entries=0, duration=47ms, bytesRcvd=0.0 B, bandwidth=0.0 B/sec, histPartitions=0, histEntries=0, histBytesRcvd=0.0 B, fullPartitions=100, fullEntries=0, fullBytesRcvd=0.0 B, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], progress=1/1]
[09:19:14,857][INFO][rebalance-#98][GridDhtPartitionDemander] Completed rebalance future: RebalanceFuture [state=STARTED, grp=CacheGroupContext [grp=ignite-sys-cache], topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], rebalanceId=1, routines=1, receivedBytes=1200, receivedKeys=0, partitionsLeft=0, partitionsTotal=100, startTime=1717463954809, endTime=1717463954857, lastCancelledTime=-1, result=true]
[09:19:14,857][INFO][rebalance-#98][GridDhtPartitionDemander] Prepared rebalancing [grp=my_cache, mode=ASYNC, supplier=fcb17b28-510d-4c0b-b678-9eee64710d12, partitionsCount=512, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], rebalanceId=1]
[09:19:14,866][INFO][sys-#81][GridDhtPartitionDemander] Starting rebalance routine [my_cache, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], supplier=fcb17b28-510d-4c0b-b678-9eee64710d12, fullPartitions=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511], histPartitions=[], rebalanceId=1]
[09:19:14,883][INFO][main][IgniteKernal] Security status [authentication=off, sandbox=off, tls/ssl=off]
[09:19:14,883][INFO][main][IgniteKernal] Performance suggestions for grid  (fix if possible)
[09:19:14,883][INFO][main][IgniteKernal] To disable, set -DIGNITE_PERFORMANCE_SUGGESTIONS_DISABLED=true
[09:19:14,883][INFO][main][IgniteKernal]   ^-- Switch to the most recent 11 JVM version
[09:19:14,884][INFO][main][IgniteKernal]   ^-- Set max direct memory size if getting 'OOME: Direct buffer memory' (add '-XX:MaxDirectMemorySize=<size>[g|G|m|M|k|K]' to JVM options)
[09:19:14,884][INFO][main][IgniteKernal]   ^-- Enable ATOMIC mode if not using transactions (set 'atomicityMode' to ATOMIC)
[09:19:14,884][INFO][main][IgniteKernal] Refer to this page for more performance suggestions: https://ignite.apache.org/docs/latest/perf-and-troubleshooting/memory-tuning
[09:19:14,884][INFO][main][IgniteKernal] 
[09:19:14,885][INFO][main][IgniteKernal] 

>>> +-----------------------------------------------------------------------+
>>> Ignite ver. 2.16.0#20231215-sha1:7bde6a42b7fda05f8058350d30d67e57ada216d0
>>> +-----------------------------------------------------------------------+
>>> OS name: Windows 11 10.0 amd64
>>> CPU(s): 16
>>> Heap: 1.0GB
>>> VM name: 7588@MSI
>>> Local node [ID=A84EF531-529F-41B0-BF7B-AD5FD9D5FEB1, order=2, clientMode=false]
>>> Local node addresses: [MSI/0:0:0:0:0:0:0:1, /127.0.0.1, /192.168.1.201]
>>> Local ports: TCP:10800 TCP:11211 TCP:47100 UDP:47400 TCP:47500 
>>> +-----------------------------------------------------------------------+

[09:19:14,887][INFO][main][GridDiscoveryManager] Topology snapshot [ver=2, locNode=a84ef531, servers=2, clients=0, state=ACTIVE, CPUs=24, offheap=6.4GB, heap=5.0GB, aliveNodes=[TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42], TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:19:14,887][INFO][main][GridDiscoveryManager]   ^-- Baseline [id=0, size=2, online=2, offline=0]
[09:19:14,887][INFO][main][G] Node started : [stage="Configure system pool" (52 ms),stage="Start managers" (414 ms),stage="Configure binary metadata" (39 ms),stage="Start processors" (431 ms),stage="Init metastore" (17 ms),stage="Finish recovery" (0 ms),stage="Join topology" (2074 ms),stage="Await transition" (14 ms),stage="Await exchange" (546 ms),stage="Total time" (3587 ms)]
[09:19:14,910][INFO][rebalance-#100][GridDhtPartitionDemander] Completed (final) rebalancing [rebalanceId=1, grp=my_cache, supplier=fcb17b28-510d-4c0b-b678-9eee64710d12, partitions=512, entries=0, duration=53ms, bytesRcvd=0.0 B, bandwidth=0.0 B/sec, histPartitions=0, histEntries=0, histBytesRcvd=0.0 B, fullPartitions=512, fullEntries=0, fullBytesRcvd=0.0 B, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], progress=1/1]
[09:19:14,910][INFO][rebalance-#100][GridDhtPartitionDemander] Completed rebalance future: RebalanceFuture [state=STARTED, grp=CacheGroupContext [grp=my_cache], topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], rebalanceId=1, routines=1, receivedBytes=6144, receivedKeys=0, partitionsLeft=0, partitionsTotal=512, startTime=1717463954857, endTime=1717463954910, lastCancelledTime=-1, result=true]
[09:19:14,915][INFO][rebalance-#100][GridDhtPartitionDemander] Completed rebalance chain: [rebalanceId=1, partitions=612, entries=0, duration=106ms, bytesRcvd=0.0 B]
[09:19:14,974][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], crd=false, evt=DISCOVERY_CUSTOM_EVT, evtNode=fcb17b28-510d-4c0b-b678-9eee64710d12, customEvt=CacheAffinityChangeMessage [id=dad43d0ef81-a9bd3272-1173-444c-bb8c-0ba42fe85891, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=0], exchId=null, partsMsg=null, exchangeNeeded=true, stopProc=false], allowMerge=false, exchangeFreeSwitch=false]
[09:19:14,979][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:19:15,004][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ClientLatch [coordinator=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], ackSent=true, super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=1]]]]
[09:19:15,004][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:19:15,006][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], crd=false]
[09:19:15,039][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Received full message, will finish exchange [node=fcb17b28-510d-4c0b-b678-9eee64710d12, resVer=AffinityTopologyVersion [topVer=2, minorTopVer=1]]
[09:19:15,040][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], err=null, rebalanced=true, wasRebalanced=false]
[09:19:15,041][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=2, minorTopVer=1]]
[09:19:15,041][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (1 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (3 ms), stage="Wait partitions release latch [latch=exchange]" (24 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for Full message" (34 ms), stage="Affinity recalculation" (0 ms), stage="Full map updating" (1 ms), stage="Exchange done" (0 ms), stage="Total time" (63 ms)]
[09:19:15,041][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=1], stage="Affinity change by custom message [grp=my_cache]" (1 ms) (parent=Determine exchange type), stage="Affinity change by custom message [grp=ignite-sys-cache]" (1 ms) (parent=Determine exchange type)]
[09:19:15,041][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=2, minorTopVer=1], force=false, evt=DISCOVERY_CUSTOM_EVT, node=fcb17b28-510d-4c0b-b678-9eee64710d12]
[09:19:24,423][INFO][ignite-update-notifier-timer][GridUpdateNotifier] Your version is up to date.
[09:19:58,914][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], crd=false, evt=DISCOVERY_CUSTOM_EVT, evtNode=fcb17b28-510d-4c0b-b678-9eee64710d12, customEvt=DynamicCacheChangeBatch [id=81f43d0ef81-a9bd3272-1173-444c-bb8c-0ba42fe85891, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=tx_cache, hasCfg=true, nodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, clientStartOnly=false, stop=false, destroy=false, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=[tx_cache], stopCaches=null, startGrps=[tx_cache], stopGrps=[], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[09:19:58,924][INFO][exchange-worker-#77][GridCacheProcessor] Started cache [name=tx_cache, id=-2051985913, dataRegionName=default, mode=PARTITIONED, atomicity=TRANSACTIONAL, backups=0]
[09:19:58,947][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:19:59,001][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ClientLatch [coordinator=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], ackSent=true, super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=2]]]]
[09:19:59,002][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:19:59,041][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], crd=false]
[09:19:59,075][INFO][sys-#89][GridDhtPartitionsExchangeFuture] Received full message, will finish exchange [node=fcb17b28-510d-4c0b-b678-9eee64710d12, resVer=AffinityTopologyVersion [topVer=2, minorTopVer=2]]
[09:19:59,076][INFO][sys-#89][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], err=null, rebalanced=true, wasRebalanced=true]
[09:19:59,077][INFO][sys-#89][GridCacheProcessor] Finish proxy initialization, cacheName=tx_cache, localNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1
[09:19:59,077][INFO][sys-#89][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=2, minorTopVer=2]]
[09:19:59,077][INFO][sys-#89][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (3 ms), stage="Update caches registry" (3 ms), stage="Start caches" (9 ms), stage="Affinity initialization on cache group start" (19 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (1 ms), stage="Wait partitions release latch [latch=exchange]" (53 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (35 ms), stage="WAL history reservation" (0 ms), stage="Waiting for Full message" (37 ms), stage="Affinity recalculation" (0 ms), stage="Full map updating" (0 ms), stage="Exchange done" (1 ms), stage="Total time" (161 ms)]
[09:19:59,077][INFO][sys-#89][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=2], stage="Affinity initialization on cache group start [grp=tx_cache]" (19 ms) (parent=Affinity initialization on cache group start)]
[09:19:59,078][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=2, minorTopVer=2], force=false, evt=DISCOVERY_CUSTOM_EVT, node=fcb17b28-510d-4c0b-b678-9eee64710d12]
[09:20:01,571][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], crd=false, evt=DISCOVERY_CUSTOM_EVT, evtNode=fcb17b28-510d-4c0b-b678-9eee64710d12, customEvt=DynamicCacheChangeBatch [id=54f43d0ef81-a9bd3272-1173-444c-bb8c-0ba42fe85891, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=tx_cache, hasCfg=false, nodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, clientStartOnly=false, stop=true, destroy=true, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=null, stopCaches=[tx_cache], startGrps=[], stopGrps=[tx_cache, destroy=true], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[09:20:01,573][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:20:01,590][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ClientLatch [coordinator=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], ackSent=true, super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=3]]]]
[09:20:01,590][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:20:01,592][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], crd=false]
[09:20:01,647][INFO][sys-#83][GridDhtPartitionsExchangeFuture] Received full message, will finish exchange [node=fcb17b28-510d-4c0b-b678-9eee64710d12, resVer=AffinityTopologyVersion [topVer=2, minorTopVer=3]]
[09:20:01,648][INFO][sys-#83][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], err=null, rebalanced=true, wasRebalanced=true]
[09:20:02,897][INFO][sys-#83][GridCacheProcessor] Stopped cache [cacheName=tx_cache]
[09:20:02,948][INFO][sys-#83][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=2, minorTopVer=3]]
[09:20:02,949][INFO][sys-#83][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Update caches registry" (0 ms), stage="Start caches" (0 ms), stage="Affinity initialization on cache group start" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (16 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for Full message" (56 ms), stage="Affinity recalculation" (0 ms), stage="Full map updating" (0 ms), stage="Exchange done" (1299 ms), stage="Total time" (1371 ms)]
[09:20:02,949][INFO][sys-#83][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=3], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=3]]
[09:20:02,950][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=2, minorTopVer=3], force=false, evt=DISCOVERY_CUSTOM_EVT, node=fcb17b28-510d-4c0b-b678-9eee64710d12]
[09:20:02,960][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], crd=false, evt=DISCOVERY_CUSTOM_EVT, evtNode=fcb17b28-510d-4c0b-b678-9eee64710d12, customEvt=DynamicCacheChangeBatch [id=6ef43d0ef81-a9bd3272-1173-444c-bb8c-0ba42fe85891, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=tx_cache, hasCfg=true, nodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, clientStartOnly=false, stop=false, destroy=false, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=[tx_cache], stopCaches=null, startGrps=[tx_cache], stopGrps=[], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[09:20:02,961][INFO][exchange-worker-#77][GridCacheProcessor] Started cache [name=tx_cache, id=-2051985913, dataRegionName=default, mode=PARTITIONED, atomicity=TRANSACTIONAL, backups=0]
[09:20:02,966][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:20:03,033][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ClientLatch [coordinator=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], ackSent=true, super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=4]]]]
[09:20:03,034][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:20:03,045][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], crd=false]
[09:20:03,203][INFO][sys-#81][GridDhtPartitionsExchangeFuture] Received full message, will finish exchange [node=fcb17b28-510d-4c0b-b678-9eee64710d12, resVer=AffinityTopologyVersion [topVer=2, minorTopVer=4]]
[09:20:03,205][INFO][sys-#81][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], err=null, rebalanced=true, wasRebalanced=true]
[09:20:03,206][INFO][sys-#81][GridCacheProcessor] Finish proxy initialization, cacheName=tx_cache, localNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1
[09:20:03,206][INFO][sys-#81][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=2, minorTopVer=4]]
[09:20:03,206][INFO][sys-#81][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Update caches registry" (0 ms), stage="Start caches" (2 ms), stage="Affinity initialization on cache group start" (2 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (68 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (9 ms), stage="WAL history reservation" (0 ms), stage="Waiting for Full message" (160 ms), stage="Affinity recalculation" (0 ms), stage="Full map updating" (1 ms), stage="Exchange done" (1 ms), stage="Total time" (243 ms)]
[09:20:03,206][INFO][sys-#81][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=4], stage="Affinity initialization on cache group start [grp=tx_cache]" (2 ms) (parent=Affinity initialization on cache group start)]
[09:20:03,208][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=2, minorTopVer=4], force=false, evt=DISCOVERY_CUSTOM_EVT, node=fcb17b28-510d-4c0b-b678-9eee64710d12]
[09:20:05,427][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], crd=false, evt=DISCOVERY_CUSTOM_EVT, evtNode=fcb17b28-510d-4c0b-b678-9eee64710d12, customEvt=DynamicCacheChangeBatch [id=0b053d0ef81-a9bd3272-1173-444c-bb8c-0ba42fe85891, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=tx_cache, hasCfg=false, nodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, clientStartOnly=false, stop=true, destroy=true, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=null, stopCaches=[tx_cache], startGrps=[], stopGrps=[tx_cache, destroy=true], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[09:20:05,429][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:20:05,446][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ClientLatch [coordinator=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], ackSent=true, super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=2, minorTopVer=5]]]]
[09:20:05,447][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:20:05,458][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], crd=false]
[09:20:05,491][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Received full message, will finish exchange [node=fcb17b28-510d-4c0b-b678-9eee64710d12, resVer=AffinityTopologyVersion [topVer=2, minorTopVer=5]]
[09:20:05,493][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], err=null, rebalanced=true, wasRebalanced=true]
[09:20:06,629][INFO][sys-#86][GridCacheProcessor] Stopped cache [cacheName=tx_cache]
[09:20:06,644][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=2, minorTopVer=5]]
[09:20:06,645][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Update caches registry" (0 ms), stage="Start caches" (0 ms), stage="Affinity initialization on cache group start" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (17 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (4 ms), stage="WAL history reservation" (0 ms), stage="Waiting for Full message" (39 ms), stage="Affinity recalculation" (0 ms), stage="Full map updating" (1 ms), stage="Exchange done" (1151 ms), stage="Total time" (1212 ms)]
[09:20:06,645][INFO][sys-#86][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=2, minorTopVer=5], resVer=AffinityTopologyVersion [topVer=2, minorTopVer=5]]
[09:20:06,647][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=2, minorTopVer=5], force=false, evt=DISCOVERY_CUSTOM_EVT, node=fcb17b28-510d-4c0b-b678-9eee64710d12]
[09:20:14,882][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:01:00.006]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=2, minorTopVer=5]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=77MB, free=92.42%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:21:14,891][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:02:00.017]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=2, minorTopVer=5]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.07%, GC=0%]
    ^-- Heap [used=80MB, free=92.13%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:21:40,417][WARNING][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][TcpDiscoverySpi] Timed out waiting for message delivery receipt (most probably, the reason is in long GC pauses on remote node; consider tuning GC and increasing 'ackTimeout' configuration property). Will retry to send message with increased timeout [currentTimeout=9491, rmtAddr=/192.168.1.133:47500, rmtPort=47500]
[09:21:40,423][WARNING][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][TcpDiscoverySpi] Failed to send message to next node [msg=TcpDiscoveryConnectionCheckMessage [super=TcpDiscoveryAbstractMessage [sndNodeId=null, id=7ae24d0ef81-a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, verifierNodeId=null, topVer=0, pendingIdx=0, failedNodes=null, isClient=false]], next=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], errMsg=Failed to send message to next node [msg=TcpDiscoveryConnectionCheckMessage [super=TcpDiscoveryAbstractMessage [sndNodeId=null, id=7ae24d0ef81-a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, verifierNodeId=null, topVer=0, pendingIdx=0, failedNodes=null, isClient=false]], next=ClusterNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, order=1, addr=[0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133]]]]
[09:21:40,424][WARNING][tcp-disco-msg-worker-[fcb17b28 192.168.1.133:47500]-#2-#69][TcpDiscoverySpi] Local node has detected failed nodes and started cluster-wide procedure. To speed up failure detection please see 'Failure Detection' section under javadoc for 'TcpDiscoverySpi'
[09:21:40,432][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/0:0:0:0:0:0:0:1, rmtPort=63672]
[09:21:40,433][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/0:0:0:0:0:0:0:1, rmtPort=63672]
[09:21:40,434][INFO][tcp-disco-sock-reader-[]-#8-#114][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/[0:0:0:0:0:0:0:1]:63672, rmtPort=63672]
[09:21:40,435][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: fcb17b28-510d-4c0b-b678-9eee64710d12
[09:21:40,435][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:21:40,436][INFO][tcp-disco-sock-reader-[a84ef531 0:0:0:0:0:0:0:1:63672]-#8-#114][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/[0:0:0:0:0:0:0:1]:63672, rmtPort=63672, rmtNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:21:40,436][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:21:40,436][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:21:40,437][WARNING][disco-event-worker-#75][GridDiscoveryManager] Node FAILED: TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:21:40,439][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/127.0.0.1, rmtPort=63673]
[09:21:40,439][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/127.0.0.1, rmtPort=63673]
[09:21:40,440][INFO][tcp-disco-sock-reader-[]-#9-#115][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/127.0.0.1:63673, rmtPort=63673]
[09:21:40,441][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=3, locNode=a84ef531, servers=1, clients=0, state=ACTIVE, CPUs=16, offheap=3.2GB, heap=1.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:21:40,441][INFO][tcp-disco-sock-reader-[a84ef531 127.0.0.1:63673]-#9-#115][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/127.0.0.1:63673, rmtPort=63673, rmtNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:21:40,442][INFO][disco-event-worker-#75][GridDiscoveryManager] Coordinator changed [prev=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], cur=TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, addrs=ArrayList [0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], sockAddrs=HashSet [MSI/192.168.1.201:47500, /[0:0:0:0:0:0:0:1]:47500, /127.0.0.1:47500], discPort=47500, order=2, intOrder=2, lastExchangeTime=1717464100413, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]]
[09:21:40,442][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=1, online=1, offline=0]
[09:21:40,449][INFO][disco-event-worker-#75][MvccProcessorImpl] Assigned mvcc coordinator [crd=MvccCoordinator [topVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, ver=1717463896734, local=true, initialized=false]]
[09:21:40,485][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], crd=true, evt=NODE_FAILED, evtNode=fcb17b28-510d-4c0b-b678-9eee64710d12, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:21:40,489][INFO][sys-#118][ExchangeLatchManager] Become new coordinator a84ef531-529f-41b0-bf7b-ad5fd9d5feb1
[09:21:40,494][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:21:40,496][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=3, minorTopVer=0]]]]
[09:21:40,496][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:21:40,503][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=3, minorTopVer=0]]
[09:21:40,504][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=3, minorTopVer=0]]
[09:21:40,542][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], err=null, rebalanced=true, wasRebalanced=true]
[09:21:40,544][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], evt=NODE_FAILED, evtNode=TcpDiscoveryNode [id=fcb17b28-510d-4c0b-b678-9eee64710d12, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1717463954019, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=3, minorTopVer=0]]
[09:21:40,544][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (8 ms), stage="Wait partitions release latch [latch=exchange]" (1 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Finalize update counters" (6 ms), stage="Waiting for all single messages" (0 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (22 ms), stage="Collect update counters and create affinity messages" (3 ms), stage="Assign partitions states" (4 ms), stage="Validate partitions states" (4 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (2 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Detect lost partitions" (0 ms), stage="Exchange done" (0 ms), stage="Total time" (50 ms)]
[09:21:40,544][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], stage="Affinity recalculation (partitions availability) [grp=my_cache]" (10 ms) (parent=Affinity recalculation (crd)), stage="Affinity recalculation (partitions availability) [grp=ignite-sys-cache]" (10 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (enforced) [grp=my_cache]" (4 ms) (parent=Affinity recalculation (crd))]
[09:21:40,544][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=3, minorTopVer=0], crd=true]
[09:21:40,545][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=3, minorTopVer=0], force=false, evt=NODE_FAILED, node=fcb17b28-510d-4c0b-b678-9eee64710d12]
[09:21:43,174][INFO][grid-nio-worker-tcp-comm-1-#40%TcpCommunicationSpi%][TcpCommunicationSpi] Accepted incoming communication connection [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61527]
[09:21:43,182][WARNING][grid-nio-worker-tcp-comm-1-#40%TcpCommunicationSpi%][TcpCommunicationSpi] Close incoming connection, unknown node [nodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, ses=GridSelectorNioSessionImpl [worker=DirectNioClientWorker [super=AbstractNioClientWorker [idx=1, bytesRcvd=42, bytesSent=18, bytesRcvd0=42, bytesSent0=18, select=true, super=GridWorker [name=grid-nio-worker-tcp-comm-1, igniteInstanceName=TcpCommunicationSpi, finished=false, heartbeatTs=1717464103169, hashCode=926188233, interrupted=false, runner=grid-nio-worker-tcp-comm-1-#40%TcpCommunicationSpi%]]], writeBuf=java.nio.DirectByteBuffer[pos=0 lim=32768 cap=32768], readBuf=java.nio.DirectByteBuffer[pos=42 lim=42 cap=32768], inRecovery=null, outRecovery=null, closeSocket=true, outboundMessagesQueueSizeMetric=o.a.i.i.processors.metric.impl.LongAdderMetric@69a257d1, super=GridNioSessionImpl [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61527, createTime=1717464103169, closeTime=0, bytesSent=18, bytesRcvd=42, bytesSent0=18, bytesRcvd0=42, sndSchedTime=1717464103169, lastSndTime=1717464103169, lastRcvTime=1717464103169, readsPaused=false, filterChain=FilterChain[filters=[GridNioCodecFilter [parser=o.a.i.i.util.nio.GridDirectParser@306aa81f, directMode=true], GridConnectionBytesVerifyFilter], accepted=true, markedForClose=false]]]
[09:21:43,207][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61528]
[09:21:43,208][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61528]
[09:21:43,209][INFO][tcp-disco-sock-reader-[]-#10-#128][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61528, rmtPort=61528]
[09:21:43,214][INFO][tcp-disco-sock-reader-[]-#10-#128][TcpDiscoverySpi] Received ping request from the remote node [rmtNodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, rmtAddr=/192.168.1.133:61528, rmtPort=61528]
[09:21:43,215][INFO][tcp-disco-sock-reader-[]-#10-#128][TcpDiscoverySpi] Finished writing ping response [rmtNodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, rmtAddr=/192.168.1.133:61528, rmtPort=61528]
[09:21:43,215][INFO][tcp-disco-sock-reader-[]-#10-#128][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61528, rmtPort=61528, rmtNodeId=null]
[09:21:43,243][INFO][grid-nio-worker-tcp-comm-2-#41%TcpCommunicationSpi%][TcpCommunicationSpi] Accepted incoming communication connection [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61529]
[09:21:43,252][WARNING][grid-nio-worker-tcp-comm-2-#41%TcpCommunicationSpi%][TcpCommunicationSpi] Close incoming connection, unknown node [nodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, ses=GridSelectorNioSessionImpl [worker=DirectNioClientWorker [super=AbstractNioClientWorker [idx=2, bytesRcvd=42, bytesSent=18, bytesRcvd0=42, bytesSent0=18, select=true, super=GridWorker [name=grid-nio-worker-tcp-comm-2, igniteInstanceName=TcpCommunicationSpi, finished=false, heartbeatTs=1717464103247, hashCode=1342917683, interrupted=false, runner=grid-nio-worker-tcp-comm-2-#41%TcpCommunicationSpi%]]], writeBuf=java.nio.DirectByteBuffer[pos=0 lim=32768 cap=32768], readBuf=java.nio.DirectByteBuffer[pos=42 lim=42 cap=32768], inRecovery=null, outRecovery=null, closeSocket=true, outboundMessagesQueueSizeMetric=o.a.i.i.processors.metric.impl.LongAdderMetric@69a257d1, super=GridNioSessionImpl [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61529, createTime=1717464103231, closeTime=0, bytesSent=18, bytesRcvd=42, bytesSent0=18, bytesRcvd0=42, sndSchedTime=1717464103231, lastSndTime=1717464103231, lastRcvTime=1717464103247, readsPaused=false, filterChain=FilterChain[filters=[GridNioCodecFilter [parser=o.a.i.i.util.nio.GridDirectParser@306aa81f, directMode=true], GridConnectionBytesVerifyFilter], accepted=true, markedForClose=false]]]
[09:21:43,269][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61530]
[09:21:43,270][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61530]
[09:21:43,270][INFO][tcp-disco-sock-reader-[]-#11-#129][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61530, rmtPort=61530]
[09:21:43,271][INFO][tcp-disco-sock-reader-[]-#11-#129][TcpDiscoverySpi] Received ping request from the remote node [rmtNodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, rmtAddr=/192.168.1.133:61530, rmtPort=61530]
[09:21:43,272][INFO][tcp-disco-sock-reader-[]-#11-#129][TcpDiscoverySpi] Finished writing ping response [rmtNodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, rmtAddr=/192.168.1.133:61530, rmtPort=61530]
[09:21:43,272][INFO][tcp-disco-sock-reader-[]-#11-#129][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61530, rmtPort=61530, rmtNodeId=null]
[09:21:43,294][INFO][grid-nio-worker-tcp-comm-3-#42%TcpCommunicationSpi%][TcpCommunicationSpi] Accepted incoming communication connection [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61531]
[09:21:43,299][WARNING][grid-nio-worker-tcp-comm-3-#42%TcpCommunicationSpi%][TcpCommunicationSpi] Close incoming connection, unknown node [nodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, ses=GridSelectorNioSessionImpl [worker=DirectNioClientWorker [super=AbstractNioClientWorker [idx=3, bytesRcvd=42, bytesSent=18, bytesRcvd0=42, bytesSent0=18, select=true, super=GridWorker [name=grid-nio-worker-tcp-comm-3, igniteInstanceName=TcpCommunicationSpi, finished=false, heartbeatTs=1717464103293, hashCode=478131586, interrupted=false, runner=grid-nio-worker-tcp-comm-3-#42%TcpCommunicationSpi%]]], writeBuf=java.nio.DirectByteBuffer[pos=0 lim=32768 cap=32768], readBuf=java.nio.DirectByteBuffer[pos=42 lim=42 cap=32768], inRecovery=null, outRecovery=null, closeSocket=true, outboundMessagesQueueSizeMetric=o.a.i.i.processors.metric.impl.LongAdderMetric@69a257d1, super=GridNioSessionImpl [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61531, createTime=1717464103293, closeTime=0, bytesSent=18, bytesRcvd=42, bytesSent0=18, bytesRcvd0=42, sndSchedTime=1717464103293, lastSndTime=1717464103293, lastRcvTime=1717464103293, readsPaused=false, filterChain=FilterChain[filters=[GridNioCodecFilter [parser=o.a.i.i.util.nio.GridDirectParser@306aa81f, directMode=true], GridConnectionBytesVerifyFilter], accepted=true, markedForClose=false]]]
[09:21:43,299][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/0:0:0:0:0:0:0:1, rmtPort=63675]
[09:21:43,299][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/0:0:0:0:0:0:0:1, rmtPort=63675]
[09:21:43,300][INFO][tcp-disco-sock-reader-[]-#12-#130][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/[0:0:0:0:0:0:0:1]:63675, rmtPort=63675]
[09:21:43,300][INFO][tcp-disco-sock-reader-[a84ef531 0:0:0:0:0:0:0:1:63675]-#12-#130][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/[0:0:0:0:0:0:0:1]:63675, rmtPort=63675, rmtNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:21:43,301][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/127.0.0.1, rmtPort=63676]
[09:21:43,301][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/127.0.0.1, rmtPort=63676]
[09:21:43,301][INFO][tcp-disco-sock-reader-[]-#13-#131][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/127.0.0.1:63676, rmtPort=63676]
[09:21:43,301][INFO][tcp-disco-sock-reader-[a84ef531 127.0.0.1:63676]-#13-#131][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/127.0.0.1:63676, rmtPort=63676, rmtNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:21:43,315][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61532]
[09:21:43,315][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61532]
[09:21:43,315][INFO][tcp-disco-sock-reader-[]-#14-#132][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61532, rmtPort=61532]
[09:21:43,316][INFO][tcp-disco-sock-reader-[]-#14-#132][TcpDiscoverySpi] Received ping request from the remote node [rmtNodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, rmtAddr=/192.168.1.133:61532, rmtPort=61532]
[09:21:43,316][INFO][tcp-disco-sock-reader-[]-#14-#132][TcpDiscoverySpi] Finished writing ping response [rmtNodeId=fcb17b28-510d-4c0b-b678-9eee64710d12, rmtAddr=/192.168.1.133:61532, rmtPort=61532]
[09:21:43,316][INFO][tcp-disco-sock-reader-[]-#14-#132][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61532, rmtPort=61532, rmtNodeId=null]
[09:21:43,816][INFO][tcp-disco-sock-reader-[fcb17b28 192.168.1.133:61493]-#6-#73][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61493, rmtPort=61493, rmtNodeId=fcb17b28-510d-4c0b-b678-9eee64710d12]
[09:22:14,894][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:03:00.020]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=3, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.06%, GC=0%]
    ^-- Heap [used=87MB, free=91.44%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=2, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:22:14,895][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=998]
[09:22:18,011][WARNING][tcp-disco-ip-finder-cleaner-#7-#74][TcpDiscoverySpi] Failed to ping node [nodeId=null]. Reached the timeout 10000ms. Cause: Connection refused: getsockopt
[09:23:14,898][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:04:00.022]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=3, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.05%, GC=0%]
    ^-- Heap [used=89MB, free=91.25%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:23:14,899][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=998]
[09:24:14,899][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:05:00.023]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=3, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.04%, GC=0%]
    ^-- Heap [used=91MB, free=91.05%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:24:14,899][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=998]
[09:24:31,362][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61558]
[09:24:31,362][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61558]
[09:24:31,362][INFO][tcp-disco-sock-reader-[]-#15-#150][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61558, rmtPort=61558]
[09:24:31,384][INFO][tcp-disco-sock-reader-[89bc73b8 192.168.1.133:61558]-#15-#150][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, rmtAddr=/192.168.1.133:61558]
[09:24:31,495][INFO][tcp-disco-sock-reader-[89bc73b8 192.168.1.133:61558]-#15-#150][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61558, rmtPort=61558, rmtNodeId=89bc73b8-4f64-4275-aeaa-aa34d2eea53f]
[09:24:31,498][INFO][tcp-disco-msg-worker-[crd]-#2-#69][GridEncryptionManager] Joining node doesn't have stored group keys [node=89bc73b8-4f64-4275-aeaa-aa34d2eea53f]
[09:24:31,507][INFO][tcp-disco-msg-worker-[crd]-#2-#69][TcpDiscoverySpi] New next node [newNext=TcpDiscoveryNode [id=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=0, intOrder=3, lastExchangeTime=1717464271408, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]]
[09:24:32,530][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61559]
[09:24:32,530][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61559]
[09:24:32,530][INFO][tcp-disco-sock-reader-[]-#16-#151][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61559, rmtPort=61559]
[09:24:32,531][INFO][tcp-disco-sock-reader-[89bc73b8 192.168.1.133:61559]-#16-#151][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, rmtAddr=/192.168.1.133:61559]
[09:24:32,564][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: 89bc73b8-4f64-4275-aeaa-aa34d2eea53f
[09:24:32,564][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:24:32,564][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:24:32,564][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:24:32,564][INFO][disco-event-worker-#75][GridDiscoveryManager] Added new node to topology: TcpDiscoveryNode [id=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=4, intOrder=3, lastExchangeTime=1717464271408, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:24:32,565][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=4, locNode=a84ef531, servers=2, clients=0, state=ACTIVE, CPUs=24, offheap=6.4GB, heap=5.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42], TcpDiscoveryNode [id=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:24:32,565][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=2, online=2, offline=0]
[09:24:32,566][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], crd=true, evt=NODE_JOINED, evtNode=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:24:32,567][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:24:32,567][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0]]]]
[09:24:32,567][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:24:32,567][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], crd=true]
[09:24:32,717][INFO][grid-nio-worker-tcp-comm-4-#43%TcpCommunicationSpi%][TcpCommunicationSpi] Accepted incoming communication connection [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61560]
[09:24:32,736][INFO][sys-#152][GridDhtPartitionsExchangeFuture] Coordinator received single message [ver=AffinityTopologyVersion [topVer=4, minorTopVer=0], node=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, allReceived=true]
[09:24:32,736][INFO][sys-#152][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=4, minorTopVer=0]]
[09:24:32,736][INFO][sys-#152][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=4, minorTopVer=0]]
[09:24:32,747][INFO][sys-#152][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], err=null, rebalanced=false, wasRebalanced=true]
[09:24:32,748][INFO][sys-#152][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], evt=NODE_JOINED, evtNode=TcpDiscoveryNode [id=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=4, intOrder=3, lastExchangeTime=1717464271408, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=false, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0]]
[09:24:32,748][INFO][sys-#152][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (168 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (4 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (0 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (1 ms), stage="Full message sending" (2 ms), stage="State finish message sending" (0 ms), stage="Exchange done" (1 ms), stage="Total time" (176 ms), Discovery lag=17992 ms, Latest started node id=89bc73b8-4f64-4275-aeaa-aa34d2eea53f]
[09:24:32,748][INFO][sys-#152][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], stage="Affinity initialization (node join) [grp=my_cache, crd=true]" (3 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (node join) [grp=ignite-sys-cache, crd=true]" (1 ms) (parent=Affinity recalculation (crd))]
[09:24:32,749][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=4, minorTopVer=0], force=false, evt=NODE_JOINED, node=89bc73b8-4f64-4275-aeaa-aa34d2eea53f]
[09:24:33,081][INFO][rebalance-striped-#163][GridDhtPartitionSupplier] Finished supplying rebalancing [grp=ignite-sys-cache, demander=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0]]
[09:24:33,145][INFO][rebalance-striped-#163][GridDhtPartitionSupplier] Finished supplying rebalancing [grp=my_cache, demander=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0]]
[09:24:33,181][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, customEvt=CacheAffinityChangeMessage [id=0df24d0ef81-e49c5930-9691-4a1b-961a-41b0579ce9f7, topVer=AffinityTopologyVersion [topVer=4, minorTopVer=0], exchId=null, partsMsg=null, exchangeNeeded=true, stopProc=false], allowMerge=false, exchangeFreeSwitch=false]
[09:24:33,181][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:24:33,198][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=4, minorTopVer=1]]]]
[09:24:33,199][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:24:33,199][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], crd=true]
[09:24:33,236][INFO][sys-#157][GridDhtPartitionsExchangeFuture] Coordinator received single message [ver=AffinityTopologyVersion [topVer=4, minorTopVer=1], node=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, allReceived=true]
[09:24:33,236][INFO][sys-#157][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=4, minorTopVer=1]]
[09:24:33,239][INFO][sys-#157][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], err=null, rebalanced=true, wasRebalanced=false]
[09:24:33,239][INFO][sys-#157][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, addrs=ArrayList [0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], sockAddrs=HashSet [MSI/192.168.1.201:47500, /[0:0:0:0:0:0:0:1]:47500, /127.0.0.1:47500], discPort=47500, order=2, intOrder=2, lastExchangeTime=1717464273228, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=4, minorTopVer=1]]
[09:24:33,239][INFO][sys-#157][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (1 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (16 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (37 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Validate partitions states" (0 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (1 ms), stage="Full message sending" (0 ms), stage="Exchange done" (0 ms), stage="Total time" (55 ms), Discovery lag=17967 ms, Latest started node id=89bc73b8-4f64-4275-aeaa-aa34d2eea53f]
[09:24:33,239][INFO][sys-#157][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=4, minorTopVer=1], stage="Affinity change by custom message [grp=my_cache]" (1 ms) (parent=Determine exchange type), stage="Affinity change by custom message [grp=ignite-sys-cache]" (0 ms) (parent=Determine exchange type)]
[09:24:33,239][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=4, minorTopVer=1], force=false, evt=DISCOVERY_CUSTOM_EVT, node=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:25:14,898][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:06:00.023]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=4, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.04%, GC=0%]
    ^-- Heap [used=111MB, free=89.1%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:25:14,898][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=998]
[09:26:14,904][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:07:00.030]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=4, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.05%, GC=0%]
    ^-- Heap [used=124MB, free=87.83%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:26:14,904][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=998]
[09:27:14,913][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:08:00.037]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=4, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0.03%, avgLoad=0.06%, GC=0%]
    ^-- Heap [used=143MB, free=85.98%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:27:14,913][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=26, reusePages=745]
[09:28:14,924][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:09:00.048]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=4, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.08%, GC=0%]
    ^-- Heap [used=163MB, free=84.02%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:28:14,924][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=77, reusePages=693]
[09:29:14,926][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:10:00.052]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=4, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0.17%, avgLoad=0.09%, GC=0%]
    ^-- Heap [used=190MB, free=81.39%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:29:14,926][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=133, reusePages=628]
[09:29:57,356][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: 89bc73b8-4f64-4275-aeaa-aa34d2eea53f
[09:29:57,356][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:29:57,356][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:29:57,357][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:29:57,357][INFO][disco-event-worker-#75][GridDiscoveryManager] Node left topology: TcpDiscoveryNode [id=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=4, intOrder=3, lastExchangeTime=1717464271408, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:29:57,359][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=5, locNode=a84ef531, servers=1, clients=0, state=ACTIVE, CPUs=16, offheap=3.2GB, heap=1.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:29:57,360][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=1, online=1, offline=0]
[09:29:57,375][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], crd=true, evt=NODE_LEFT, evtNode=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:29:57,376][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:29:57,378][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=5, minorTopVer=0]]]]
[09:29:57,378][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:29:57,382][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=5, minorTopVer=0]]
[09:29:57,383][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=5, minorTopVer=0]]
[09:29:57,395][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], err=null, rebalanced=true, wasRebalanced=true]
[09:29:57,395][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], evt=NODE_LEFT, evtNode=TcpDiscoveryNode [id=89bc73b8-4f64-4275-aeaa-aa34d2eea53f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=4, intOrder=3, lastExchangeTime=1717464271408, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=5, minorTopVer=0]]
[09:29:57,395][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (1 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Finalize update counters" (3 ms), stage="Waiting for all single messages" (0 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (10 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (0 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (0 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Detect lost partitions" (0 ms), stage="Exchange done" (0 ms), stage="Total time" (14 ms)]
[09:29:57,395][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], stage="Affinity recalculation (partitions availability) [grp=my_cache]" (8 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (enforced) [grp=my_cache]" (4 ms) (parent=Affinity recalculation (crd)), stage="Affinity recalculation (partitions availability) [grp=ignite-sys-cache]" (2 ms) (parent=Affinity recalculation (crd))]
[09:29:57,396][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=5, minorTopVer=0], crd=true]
[09:29:57,396][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=5, minorTopVer=0], force=false, evt=NODE_LEFT, node=89bc73b8-4f64-4275-aeaa-aa34d2eea53f]
[09:29:57,897][INFO][tcp-disco-sock-reader-[89bc73b8 192.168.1.133:61559]-#16-#151][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61559, rmtPort=61559, rmtNodeId=89bc73b8-4f64-4275-aeaa-aa34d2eea53f]
[09:30:14,940][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:11:00.065]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=5, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.09%, GC=0%]
    ^-- Heap [used=208MB, free=79.63%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=2, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:30:14,940][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=139, reusePages=622]
[09:30:28,226][WARNING][tcp-disco-ip-finder-cleaner-#7-#74][TcpDiscoverySpi] Failed to ping node [nodeId=null]. Was unable to open the socket at all. Cause: no such interface lo0
[09:30:29,656][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61618]
[09:30:29,657][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61618]
[09:30:29,658][INFO][tcp-disco-sock-reader-[]-#17-#226][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61618, rmtPort=61618]
[09:30:29,660][INFO][tcp-disco-sock-reader-[23cbaa53 192.168.1.133:61618]-#17-#226][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, rmtAddr=/192.168.1.133:61618]
[09:30:29,759][INFO][tcp-disco-sock-reader-[23cbaa53 192.168.1.133:61618]-#17-#226][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61618, rmtPort=61618, rmtNodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f]
[09:30:29,760][INFO][tcp-disco-msg-worker-[crd]-#2-#69][GridEncryptionManager] Joining node doesn't have stored group keys [node=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f]
[09:30:29,764][INFO][tcp-disco-msg-worker-[crd]-#2-#69][TcpDiscoverySpi] New next node [newNext=TcpDiscoveryNode [id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=0, intOrder=4, lastExchangeTime=1717464629703, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]]
[09:30:32,159][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61619]
[09:30:32,159][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61619]
[09:30:32,161][INFO][tcp-disco-sock-reader-[]-#18-#231][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61619, rmtPort=61619]
[09:30:32,163][INFO][tcp-disco-sock-reader-[23cbaa53 192.168.1.133:61619]-#18-#231][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, rmtAddr=/192.168.1.133:61619]
[09:30:32,270][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: 23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f
[09:30:32,270][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:30:32,270][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:30:32,270][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:30:32,271][INFO][disco-event-worker-#75][GridDiscoveryManager] Added new node to topology: TcpDiscoveryNode [id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=6, intOrder=4, lastExchangeTime=1717464629703, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:30:32,273][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=6, locNode=a84ef531, servers=2, clients=0, state=ACTIVE, CPUs=24, offheap=6.4GB, heap=5.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42], TcpDiscoveryNode [id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:30:32,273][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=2, online=2, offline=0]
[09:30:32,274][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], crd=true, evt=NODE_JOINED, evtNode=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:30:32,276][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:30:32,276][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0]]]]
[09:30:32,277][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:30:32,277][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], crd=true]
[09:30:32,469][INFO][grid-nio-worker-tcp-comm-5-#44%TcpCommunicationSpi%][TcpCommunicationSpi] Accepted incoming communication connection [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61620]
[09:30:32,497][INFO][sys-#218][GridDhtPartitionsExchangeFuture] Coordinator received single message [ver=AffinityTopologyVersion [topVer=6, minorTopVer=0], node=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, allReceived=true]
[09:30:32,498][INFO][sys-#218][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=6, minorTopVer=0]]
[09:30:32,498][INFO][sys-#218][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=6, minorTopVer=0]]
[09:30:32,520][INFO][sys-#218][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], err=null, rebalanced=false, wasRebalanced=true]
[09:30:32,522][INFO][sys-#218][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], evt=NODE_JOINED, evtNode=TcpDiscoveryNode [id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=6, intOrder=4, lastExchangeTime=1717464629703, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=false, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0]]
[09:30:32,522][INFO][sys-#218][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (220 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (11 ms), stage="Collect update counters and create affinity messages" (1 ms), stage="Assign partitions states" (1 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (1 ms), stage="Full message preparing" (5 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Exchange done" (1 ms), stage="Total time" (241 ms), Discovery lag=18016 ms, Latest started node id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f]
[09:30:32,523][INFO][sys-#218][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], stage="Affinity initialization (node join) [grp=my_cache, crd=true]" (9 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (node join) [grp=ignite-sys-cache, crd=true]" (3 ms) (parent=Affinity recalculation (crd))]
[09:30:32,524][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=6, minorTopVer=0], force=false, evt=NODE_JOINED, node=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f]
[09:30:32,674][INFO][rebalance-striped-#234][GridDhtPartitionSupplier] Finished supplying rebalancing [grp=ignite-sys-cache, demander=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0]]
[09:30:32,753][INFO][rebalance-striped-#234][GridDhtPartitionSupplier] Finished supplying rebalancing [grp=my_cache, demander=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0]]
[09:30:40,236][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, customEvt=CacheAffinityChangeMessage [id=a1774d0ef81-e49c5930-9691-4a1b-961a-41b0579ce9f7, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=0], exchId=null, partsMsg=null, exchangeNeeded=true, stopProc=false], allowMerge=false, exchangeFreeSwitch=false]
[09:30:40,237][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:30:40,253][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1]]]]
[09:30:40,254][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:30:40,254][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], crd=true]
[09:30:40,271][INFO][sys-#209][GridDhtPartitionsExchangeFuture] Coordinator received single message [ver=AffinityTopologyVersion [topVer=6, minorTopVer=1], node=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, allReceived=true]
[09:30:40,271][INFO][sys-#209][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=6, minorTopVer=1]]
[09:30:40,274][INFO][sys-#209][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], err=null, rebalanced=true, wasRebalanced=false]
[09:30:40,274][INFO][sys-#209][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, addrs=ArrayList [0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], sockAddrs=HashSet [MSI/192.168.1.201:47500, /[0:0:0:0:0:0:0:1]:47500, /127.0.0.1:47500], discPort=47500, order=2, intOrder=2, lastExchangeTime=1717464640264, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1]]
[09:30:40,274][INFO][sys-#209][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (16 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (17 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (1 ms), stage="Full message sending" (0 ms), stage="Exchange done" (0 ms), stage="Total time" (35 ms), Discovery lag=17964 ms, Latest started node id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f]
[09:30:40,274][INFO][sys-#209][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], stage="Affinity change by custom message [grp=my_cache]" (0 ms) (parent=Determine exchange type), stage="Affinity change by custom message [grp=ignite-sys-cache]" (0 ms) (parent=Determine exchange type)]
[09:30:40,275][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=6, minorTopVer=1], force=false, evt=DISCOVERY_CUSTOM_EVT, node=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:31:14,946][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:12:00.072]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=6, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0.03%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=39MB, free=96.11%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:31:14,946][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=29, reusePages=731]
[09:32:14,958][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:13:00.083]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=6, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0.47%, avgLoad=0.09%, GC=0%]
    ^-- Heap [used=64MB, free=93.67%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:32:14,959][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=52, reusePages=708]
[09:33:14,522][WARNING][sys-#249][diagnostic] First 10 long running transactions [total=1]
[09:33:14,522][WARNING][sys-#249][diagnostic] >>> Transaction [startTime=09:32:07,933, curTime=09:33:14,442, tx=GridDhtTxLocal [nearNodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, nearFutId=9b3eed0ef81-884bec6f-4952-4259-b9bb-7d50bdcf8550, nearMiniId=1, nearFinFutId=null, nearFinMiniId=0, nearXidVer=GridCacheVersion [topVer=328943902, order=1717464652638, nodeOrder=6, dataCenterId=0], lb=null, super=GridDhtTxLocalAdapter [nearOnOriginatingNode=false, nearNodes=KeySetView [], dhtNodes=KeySetView [23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f], explicitLock=false, super=IgniteTxLocalAdapter [doneFlag=0, completedBase=null, commitErr=null, depEnabled=false, txState=IgniteTxStateImpl [activeCacheIds=[-479252689], recovery=false, mvccEnabled=false, mvccCachingCacheIds=[], txMap=ArrayList [IgniteTxEntry [txKey=IgniteTxKey [key=KeyCacheObjectImpl [part=0, val=0, hasValBytes=true], cacheId=-479252689], val=TxEntryValueHolder [val=CacheObjectImpl [val=null, hasValBytes=true], op=CREATE], prevVal=TxEntryValueHolder [val=null, op=NOOP], oldVal=TxEntryValueHolder [val=null, op=NOOP], entryProcessorsCol=null, ttl=-1, conflictExpireTime=-1, conflictVer=null, explicitVer=null, dhtVer=null, filters=CacheEntryPredicate[] [], filtersPassed=false, filtersSet=false, entry=GridDhtCacheEntry [rdrs=ReaderId[] [], part=0, super=GridDistributedCacheEntry [super=GridCacheMapEntry [key=KeyCacheObjectImpl [part=0, val=0, hasValBytes=true], val=CacheObjectImpl [val=null, hasValBytes=true], ver=GridCacheVersion [topVer=328943902, order=1717464645939, nodeOrder=2, dataCenterId=0], hash=0, extras=GridCacheMvccEntryExtras [mvcc=GridCacheMvcc [locs=LinkedList [GridCacheMvccCandidate [nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, ver=GridCacheVersion [topVer=328943902, order=1717464652639, nodeOrder=2, dataCenterId=0], threadId=117, id=14162, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], reentry=null, otherNodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, otherVer=GridCacheVersion [topVer=328943902, order=1717464652638, nodeOrder=6, dataCenterId=0], mappedDhtNodes=null, mappedNearNodes=null, ownerVer=null, serOrder=null, key=KeyCacheObjectImpl [part=0, val=0, hasValBytes=true], masks=local=1|owner=1|ready=1|reentry=0|used=0|tx=1|single_implicit=0|dht_local=1|near_local=0|removed=0|read=0, prevVer=null, nextVer=GridCacheVersion [topVer=328943902, order=1717464652639, nodeOrder=2, dataCenterId=0]]], rmts=null]], flags=2]]], prepared=1, locked=false, nodeId=null, locMapped=false, expiryPlc=null, transferExpiryPlc=false, flags=2, partUpdateCntr=0, serReadVer=null, xidVer=null], IgniteTxEntry [txKey=IgniteTxKey [key=KeyCacheObjectImpl [part=1, val=1, hasValBytes=true], cacheId=-479252689], val=TxEntryValueHolder [val=CacheObjectImpl [val=null, hasValBytes=true], op=CREATE], prevVal=TxEntryValueHolder [val=null, op=NOOP], oldVal=TxEntryValueHolder [val=null, op=NOOP], entryProcessorsCol=null, ttl=-1, conflictExpireTime=-1, conflictVer=null, explicitVer=null, dhtVer=null, filters=CacheEntryPredicate[] [], filtersPassed=false, filtersSet=false, entry=GridDhtCacheEntry [rdrs=ReaderId[] [], part=1, super=GridDistributedCacheEntry [super=GridCacheMapEntry [key=KeyCacheObjectImpl [part=1, val=1, hasValBytes=true], val=CacheObjectImpl [val=null, hasValBytes=true], ver=GridCacheVersion [topVer=328943902, order=1717464645942, nodeOrder=2, dataCenterId=0], hash=1, extras=GridCacheMvccEntryExtras [mvcc=GridCacheMvcc [locs=LinkedList [GridCacheMvccCandidate [nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, ver=GridCacheVersion [topVer=328943902, order=1717464652639, nodeOrder=2, dataCenterId=0], threadId=117, id=14163, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], reentry=null, otherNodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, otherVer=GridCacheVersion [topVer=328943902, order=1717464652638, nodeOrder=6, dataCenterId=0], mappedDhtNodes=null, mappedNearNodes=null, ownerVer=null, serOrder=null, key=KeyCacheObjectImpl [part=1, val=1, hasValBytes=true], masks=local=1|owner=1|ready=1|reentry=0|used=0|tx=1|single_implicit=0|dht_local=1|near_local=0|removed=0|read=0, prevVer=GridCacheVersion [topVer=328943902, order=1717464652639, nodeOrder=2, dataCenterId=0], nextVer=null]], rmts=null]], flags=2]]], prepared=1, locked=false, nodeId=null, locMapped=false, expiryPlc=null, transferExpiryPlc=false, flags=2, partUpdateCntr=0, serReadVer=null, xidVer=null], IgniteTxEntry [txKey=IgniteTxKey [key=KeyCacheObjectImpl [part=4, val=4, hasValBytes=true], cacheId=-479252689], val=TxEntryValueHolder [val=CacheObjectImpl [val=null, hasValBytes=true], op=CREATE], prevVal=TxEntryValueHolder [val=null, op=NOOP], oldVal=TxEntryValueHolder [val=null, op=NOOP], entryProcessorsCol=null, ttl=-1, conflictExpireTime=-1, conflictVer=null, explicitVer=null, dhtVer=null, filters=CacheEntryPredicate[] [], filtersPassed=false, filtersSet=false, entry=GridDhtCacheEntry [rdrs=ReaderId[] [], part=4, super=GridDistributedCacheEntry [super=GridCacheMapEntry [key=KeyCacheObjectImpl [part=4, val=4, hasValBytes=true], val=CacheObjectImpl [val=null, hasValBytes=true], ver=GridCacheVersion [topVer=328943902, order=1717464645949, nodeOrder=2, dataCenterId=0], hash=4, extras=GridCacheMvccEntryExtras [mvcc=GridCacheMvcc [locs=LinkedList [GridCacheMvccCandidate [nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, ver=GridCacheVersion [topVer=328943902, order=1717464652639, nodeOrder=2, dataCenterId=0], threadId=117, id=14164, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], reentry=null, otherNodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, otherVer=GridCacheVersion [topVer=328943902, order=1717464652638, nodeOrder=6, dataCenterId=0], mappedDhtNodes=null, mappedNearNodes=null, ownerVer=null, serOrder=null, key=KeyCacheObjectImpl [part=4, val=4, hasValBytes=true], masks=local=1|owner=1|ready=1|reentry=0|used=0|tx=1|single_implicit=0|dht_local=1|near_local=0|removed=0|read=0, prevVer=null, nextVer=null]], rmts=null]], flags=2]]], prepared=1, locked=false, nodeId=null, locMapped=false, expiryPlc=null, transferExpiryPlc=false, flags=2, partUpdateCntr=0, serReadVer=null, xidVer=null], IgniteTxEntry [txKey=IgniteTxKey [key=KeyCacheObjectImpl [part=7, val=7, hasValBytes=true], cacheId=-479252689], val=TxEntryValueHolder [val=CacheObjectImpl [val=null, hasValBytes=true], op=CREATE], prevVal=TxEntryValueHolder [val=null, op=NOOP], oldVal=TxEntryValueHolder [val=null, op=NOOP], entryProcessorsCol=null, ttl=-1, conflictExpireTime=-1, conflictVer=null, explicitVer=null, dhtVer=null, filters=CacheEntryPredicate[] [], filtersPassed=false, filtersSet=false, entry=GridDhtCacheEntry [rdrs=ReaderId[] [], part=7, super=GridDistributedCacheEntry [super=GridCacheMapEntry [key=KeyCacheObjectImpl [part=7, val=7, hasValBytes=true], val=CacheObjectImpl [val=null, hasValBytes=true], ver=GridCacheVersion [topVer=328943902, order=1717464645956, nodeOrder=2, dataCenterId=0], hash=7, extras=GridCacheMvccEntryExtras [mvcc=GridCacheMvcc [locs=LinkedList [GridCacheMvccCandidate [nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, ver=GridCacheVersion [topVer=328943902, order=1717464652639, nodeOrder=2, dataCenterId=0], threadId=117, id=14165, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], reentry=null, otherNodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, otherVer=GridCacheVersion [topVer=328943902, order=1717464652638, nodeOrder=6, dataCenterId=0], mappedDhtNodes=null, mappedNearNodes=null, ownerVer=null, serOrder=null, key=KeyCacheObjectImpl [part=7, val=7, hasValBytes=true], masks=local=1|owner=1|ready=1|reentry=0|used=0|tx=1|single_implicit=0|dht_local=1|near_local=0|removed=0|read=0, prevVer=null, nextVer=null]], rmts=null]], flags=2]]], prepared=1, locked=false, nodeId=null, locMapped=false, expiryPlc=null, transferExpiryPlc=false, flags=2, partUpdateCntr=0, serReadVer=null, xidVer=null], IgniteTxEntry [txKey=IgniteTxKey [key=KeyCacheObjectImpl [part=11, val=11, hasValBytes=true], cacheId=-479252689], val=TxEntryValueHolder [val=CacheObjectImpl [val=null, hasValBytes=true], op=CREATE], prevVal=TxEntryValueHolder [val=null, op=NOOP], oldVal=TxEntryValueHolder [val=null, op=NOOP], entryPro... and 2314 skipped ...s=true], val=CacheObjectImpl [val=null, hasValBytes=true], ver=GridCacheVersion [topVer=328943902, order=1717464646448, nodeOrder=2, dataCenterId=0], hash=205, extras=GridCacheMvccEntryExtras [mvcc=GridCacheMvcc [locs=LinkedList [GridCacheMvccCandidate [nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, ver=GridCacheVersion [topVer=328943902, order=1717464652639, nodeOrder=2, dataCenterId=0], threadId=117, id=14261, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], reentry=null, otherNodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, otherVer=GridCacheVersion [topVer=328943902, order=1717464652638, nodeOrder=6, dataCenterId=0], mappedDhtNodes=null, mappedNearNodes=null, ownerVer=null, serOrder=null, key=KeyCacheObjectImpl [part=205, val=205, hasValBytes=true], masks=local=1|owner=1|ready=1|reentry=0|used=0|tx=1|single_implicit=0|dht_local=1|near_local=0|removed=0|read=0, prevVer=GridCacheVersion [topVer=328943902, order=1717464652639, nodeOrder=2, dataCenterId=0], nextVer=null]], rmts=null]], flags=2]]], prepared=1, locked=false, nodeId=null, locMapped=false, expiryPlc=null, transferExpiryPlc=false, flags=2, partUpdateCntr=0, serReadVer=null, xidVer=null]... and 6341 more]], syncMode=null, super=IgniteTxAdapter [xidVer=GridCacheVersion [topVer=328943902, order=1717464652639, nodeOrder=2, dataCenterId=0], writeVer=GridCacheVersion [topVer=328943902, order=1717464655752, nodeOrder=2, dataCenterId=0], implicit=false, loc=true, threadId=117, startTime=1717464727933, startTimeNanos=-1, nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, needRetVal=false, isolation=REPEATABLE_READ, concurrency=OPTIMISTIC, timeout=0, sysInvalidate=false, internal=false, sys=false, plc=2, commitVer=null, finalizing=NONE, invalidParts=null, state=PREPARING, timedOut=false, topVer=AffinityTopologyVersion [topVer=6, minorTopVer=1], subjId=null, taskNameHash=0, storeEnabled=true, mvccSnapshot=null, incSnpId=null, skipCompletedVers=false, parentTx=null, duration=66509ms, onePhaseCommit=false], size=6441]]]]
[09:33:14,970][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:14:00.095]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=6, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0.3%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=421MB, free=58.8%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:33:14,970][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=52, reusePages=708]
[09:34:14,971][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:15:00.097]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=6, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=266MB, free=73.99%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:34:14,971][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=218, reusePages=541]
[09:34:25,493][WARNING][tcp-disco-msg-worker-[23cbaa53 192.168.1.133:47500 crd]-#2-#69][TcpDiscoverySpi] Timed out waiting for message delivery receipt (most probably, the reason is in long GC pauses on remote node; consider tuning GC and increasing 'ackTimeout' configuration property). Will retry to send message with increased timeout [currentTimeout=9494, rmtAddr=/192.168.1.133:47500, rmtPort=47500]
[09:34:25,494][WARNING][tcp-disco-msg-worker-[23cbaa53 192.168.1.133:47500 crd]-#2-#69][TcpDiscoverySpi] Failed to send message to next node [msg=TcpDiscoveryConnectionCheckMessage [super=TcpDiscoveryAbstractMessage [sndNodeId=null, id=e8594d0ef81-a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, verifierNodeId=null, topVer=0, pendingIdx=0, failedNodes=null, isClient=false]], next=TcpDiscoveryNode [id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=6, intOrder=4, lastExchangeTime=1717464629703, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], errMsg=Failed to send message to next node [msg=TcpDiscoveryConnectionCheckMessage [super=TcpDiscoveryAbstractMessage [sndNodeId=null, id=e8594d0ef81-a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, verifierNodeId=null, topVer=0, pendingIdx=0, failedNodes=null, isClient=false]], next=ClusterNode [id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, order=6, addr=[0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133]]]]
[09:34:25,494][WARNING][tcp-disco-msg-worker-[23cbaa53 192.168.1.133:47500 crd]-#2-#69][TcpDiscoverySpi] Local node has detected failed nodes and started cluster-wide procedure. To speed up failure detection please see 'Failure Detection' section under javadoc for 'TcpDiscoverySpi'
[09:34:25,494][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: 23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f
[09:34:25,494][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:34:25,494][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:34:25,495][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:34:25,495][WARNING][disco-event-worker-#75][GridDiscoveryManager] Node FAILED: TcpDiscoveryNode [id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=6, intOrder=4, lastExchangeTime=1717464629703, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:34:25,495][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=7, locNode=a84ef531, servers=1, clients=0, state=ACTIVE, CPUs=16, offheap=3.2GB, heap=1.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:34:25,495][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=1, online=1, offline=0]
[09:34:25,499][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], crd=true, evt=NODE_FAILED, evtNode=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:34:25,499][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:34:25,499][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=7, minorTopVer=0]]]]
[09:34:25,499][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:34:25,500][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=7, minorTopVer=0]]
[09:34:25,500][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=7, minorTopVer=0]]
[09:34:25,505][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], err=null, rebalanced=true, wasRebalanced=true]
[09:34:25,505][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], evt=NODE_FAILED, evtNode=TcpDiscoveryNode [id=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=6, intOrder=4, lastExchangeTime=1717464629703, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=7, minorTopVer=0]]
[09:34:25,505][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Finalize update counters" (1 ms), stage="Waiting for all single messages" (0 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (2 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (0 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (0 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Detect lost partitions" (0 ms), stage="Exchange done" (0 ms), stage="Total time" (3 ms)]
[09:34:25,505][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], stage="Affinity recalculation (partitions availability) [grp=my_cache]" (2 ms) (parent=Affinity recalculation (crd)), stage="Affinity recalculation (partitions availability) [grp=ignite-sys-cache]" (0 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (enforced) [grp=my_cache]" (0 ms) (parent=Affinity recalculation (crd))]
[09:34:25,505][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=7, minorTopVer=0], crd=true]
[09:34:25,506][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=7, minorTopVer=0], force=false, evt=NODE_FAILED, node=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f]
[09:34:25,762][INFO][grid-nio-worker-tcp-comm-6-#45%TcpCommunicationSpi%][TcpCommunicationSpi] Accepted incoming communication connection [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61656]
[09:34:25,824][WARNING][grid-nio-worker-tcp-comm-6-#45%TcpCommunicationSpi%][TcpCommunicationSpi] Close incoming connection, unknown node [nodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f, ses=GridSelectorNioSessionImpl [worker=DirectNioClientWorker [super=AbstractNioClientWorker [idx=6, bytesRcvd=42, bytesSent=18, bytesRcvd0=42, bytesSent0=18, select=true, super=GridWorker [name=grid-nio-worker-tcp-comm-6, igniteInstanceName=TcpCommunicationSpi, finished=false, heartbeatTs=1717464865818, hashCode=637601866, interrupted=false, runner=grid-nio-worker-tcp-comm-6-#45%TcpCommunicationSpi%]]], writeBuf=java.nio.DirectByteBuffer[pos=0 lim=32768 cap=32768], readBuf=java.nio.DirectByteBuffer[pos=42 lim=42 cap=32768], inRecovery=null, outRecovery=null, closeSocket=true, outboundMessagesQueueSizeMetric=o.a.i.i.processors.metric.impl.LongAdderMetric@69a257d1, super=GridNioSessionImpl [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61656, createTime=1717464865756, closeTime=0, bytesSent=18, bytesRcvd=42, bytesSent0=18, bytesRcvd0=42, sndSchedTime=1717464865756, lastSndTime=1717464865756, lastRcvTime=1717464865818, readsPaused=false, filterChain=FilterChain[filters=[GridNioCodecFilter [parser=o.a.i.i.util.nio.GridDirectParser@306aa81f, directMode=true], GridConnectionBytesVerifyFilter], accepted=true, markedForClose=false]]]
[09:34:26,276][INFO][tcp-disco-sock-reader-[23cbaa53 192.168.1.133:61619]-#18-#231][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61619, rmtPort=61619, rmtNodeId=23cbaa53-ddd0-4b97-9d4e-bc7a76216c8f]
[09:34:43,854][WARNING][tcp-disco-ip-finder-cleaner-#7-#74][TcpDiscoverySpi] Failed to ping node [nodeId=null]. Reached the timeout 10000ms. Cause: Connect timed out
[09:34:43,855][WARNING][tcp-disco-ip-finder-cleaner-#7-#74][TcpDiscoverySpi] Failed to ping node [nodeId=null]. Was unable to open the socket at all. Cause: no such interface lo0
[09:34:59,791][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61665]
[09:34:59,791][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61665]
[09:34:59,792][INFO][tcp-disco-sock-reader-[]-#19-#273][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61665, rmtPort=61665]
[09:34:59,814][INFO][tcp-disco-sock-reader-[b003b5b3 192.168.1.133:61665]-#19-#273][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=b003b5b3-8c19-4966-b469-85e6952d3d25, rmtAddr=/192.168.1.133:61665]
[09:34:59,917][INFO][tcp-disco-sock-reader-[b003b5b3 192.168.1.133:61665]-#19-#273][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61665, rmtPort=61665, rmtNodeId=b003b5b3-8c19-4966-b469-85e6952d3d25]
[09:34:59,922][INFO][tcp-disco-msg-worker-[crd]-#2-#69][GridEncryptionManager] Joining node doesn't have stored group keys [node=b003b5b3-8c19-4966-b469-85e6952d3d25]
[09:34:59,936][INFO][tcp-disco-msg-worker-[crd]-#2-#69][TcpDiscoverySpi] New next node [newNext=TcpDiscoveryNode [id=b003b5b3-8c19-4966-b469-85e6952d3d25, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=0, intOrder=5, lastExchangeTime=1717464899841, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]]
[09:35:04,738][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61666]
[09:35:04,738][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61666]
[09:35:04,739][INFO][tcp-disco-sock-reader-[]-#20-#274][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61666, rmtPort=61666]
[09:35:04,740][INFO][tcp-disco-sock-reader-[b003b5b3 192.168.1.133:61666]-#20-#274][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=b003b5b3-8c19-4966-b469-85e6952d3d25, rmtAddr=/192.168.1.133:61666]
[09:35:04,865][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: b003b5b3-8c19-4966-b469-85e6952d3d25
[09:35:04,866][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:35:04,866][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:35:04,866][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:35:04,867][INFO][disco-event-worker-#75][GridDiscoveryManager] Added new node to topology: TcpDiscoveryNode [id=b003b5b3-8c19-4966-b469-85e6952d3d25, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=8, intOrder=5, lastExchangeTime=1717464899841, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:35:04,868][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=8, locNode=a84ef531, servers=2, clients=0, state=ACTIVE, CPUs=24, offheap=6.4GB, heap=5.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42], TcpDiscoveryNode [id=b003b5b3-8c19-4966-b469-85e6952d3d25, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:35:04,869][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=2, online=2, offline=0]
[09:35:04,869][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], crd=true, evt=NODE_JOINED, evtNode=b003b5b3-8c19-4966-b469-85e6952d3d25, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:35:04,870][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:35:04,871][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0]]]]
[09:35:04,871][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:35:04,871][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], crd=true]
[09:35:05,060][INFO][grid-nio-worker-tcp-comm-7-#46%TcpCommunicationSpi%][TcpCommunicationSpi] Accepted incoming communication connection [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61667]
[09:35:05,075][INFO][sys-#269][GridDhtPartitionsExchangeFuture] Coordinator received single message [ver=AffinityTopologyVersion [topVer=8, minorTopVer=0], node=b003b5b3-8c19-4966-b469-85e6952d3d25, allReceived=true]
[09:35:05,075][INFO][sys-#269][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=8, minorTopVer=0]]
[09:35:05,075][INFO][sys-#269][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=8, minorTopVer=0]]
[09:35:05,079][INFO][sys-#269][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], err=null, rebalanced=false, wasRebalanced=true]
[09:35:05,080][INFO][sys-#269][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], evt=NODE_JOINED, evtNode=TcpDiscoveryNode [id=b003b5b3-8c19-4966-b469-85e6952d3d25, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=8, intOrder=5, lastExchangeTime=1717464899841, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=false, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0]]
[09:35:05,080][INFO][sys-#269][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (203 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (2 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (0 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (0 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Exchange done" (0 ms), stage="Total time" (205 ms), Discovery lag=18020 ms, Latest started node id=b003b5b3-8c19-4966-b469-85e6952d3d25]
[09:35:05,080][INFO][sys-#269][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], stage="Affinity initialization (node join) [grp=my_cache, crd=true]" (1 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (node join) [grp=ignite-sys-cache, crd=true]" (0 ms) (parent=Affinity recalculation (crd))]
[09:35:05,080][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=8, minorTopVer=0], force=false, evt=NODE_JOINED, node=b003b5b3-8c19-4966-b469-85e6952d3d25]
[09:35:06,204][INFO][rebalance-striped-#277][GridDhtPartitionSupplier] Finished supplying rebalancing [grp=ignite-sys-cache, demander=b003b5b3-8c19-4966-b469-85e6952d3d25, topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0]]
[09:35:06,309][INFO][rebalance-striped-#277][GridDhtPartitionSupplier] Finished supplying rebalancing [grp=my_cache, demander=b003b5b3-8c19-4966-b469-85e6952d3d25, topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0]]
[09:35:14,983][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:16:00.108]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=8, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=294MB, free=71.25%, comm=1024MB]
    ^-- Outbound messages queue [size=2]
    ^-- Public thread pool [active=0, idle=2, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:35:15,845][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, customEvt=CacheAffinityChangeMessage [id=14694d0ef81-e49c5930-9691-4a1b-961a-41b0579ce9f7, topVer=AffinityTopologyVersion [topVer=8, minorTopVer=0], exchId=null, partsMsg=null, exchangeNeeded=true, stopProc=false], allowMerge=false, exchangeFreeSwitch=false]
[09:35:15,848][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:35:16,854][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1]]]]
[09:35:16,854][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:35:16,857][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], crd=true]
[09:35:16,884][INFO][sys-#265][GridDhtPartitionsExchangeFuture] Coordinator received single message [ver=AffinityTopologyVersion [topVer=8, minorTopVer=1], node=b003b5b3-8c19-4966-b469-85e6952d3d25, allReceived=true]
[09:35:16,884][INFO][sys-#265][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=8, minorTopVer=1]]
[09:35:16,891][WARNING][sys-#269][GridDhtPartitionsExchangeFuture] Partition states validation has failed for group: my_cache, msg: Partitions cache sizes are inconsistent for Part 184: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=28 ] Part 185: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 186: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 187: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 188: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 189: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 190: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 191: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 192: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 193: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 194: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 195: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 196: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 197: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 198: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 199: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 200: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 201: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 202: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 203: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 204: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 205: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 206: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 207: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 208: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 209: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 210: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 211: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 212: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 213: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 214: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 215: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 216: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 217: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 218: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 219: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 220: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 221: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 222: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 223: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 224: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 225: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 226: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 227: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 228: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 229: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 230: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 231: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 232: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 233: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 234: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 235: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 236: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 237: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 238: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 239: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 240: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 241: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 242: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 243: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 244: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 245: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 246: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 247: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 248: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 249: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 250: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 251: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 252: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 253: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 254: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 255: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 256: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 257: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 258: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 259: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 260: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 261: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 262: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 263: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 264: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 265: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 266: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 267: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 268: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 269: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 270: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 271: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 272: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 273: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 274: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 275: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 276: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 277: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 278: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 279: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 280: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 281: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 282: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 283: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 284: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 285: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 286: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 287: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 288: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 289: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 290: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 291: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 292: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 293: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 294: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 295: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 296: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 297: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 298: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 299: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 300: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 301: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 302: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 303: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 304: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 305: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 306: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 307: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 308: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 309: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 310: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 311: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 312: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 313: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 314: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 315: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 316: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 317: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 318: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 319: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 320: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 321: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 322: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 323: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 324: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 325: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 326: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 327: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 328: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 329: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 330: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 331: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 332: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 333: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 334: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 335: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 336: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 337: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 338: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 339: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 340: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 341: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 342: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 343: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 344: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 345: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 346: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 347: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 348: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 349: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 350: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 351: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 352: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 353: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 354: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 355: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 356: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 357: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 358: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 359: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 360: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 361: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 362: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 363: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 364: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 365: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 366: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 367: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 368: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 369: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 370: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 371: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 372: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 373: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 374: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 375: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 376: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 377: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 378: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 379: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 380: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 381: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 382: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 383: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 384: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 385: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 386: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 387: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 388: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 389: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 390: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 391: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 392: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 393: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 394: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 395: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 396: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 397: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 398: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 399: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 400: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 401: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 402: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 403: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 404: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 405: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 406: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 407: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 408: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 409: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 410: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 411: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 412: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 413: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 414: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 415: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 416: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 417: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 418: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 419: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 420: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 421: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 422: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 423: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 424: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 425: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 426: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 427: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 428: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 429: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 430: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 431: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 432: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 433: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 434: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 435: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 436: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 437: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 438: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 439: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 440: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 441: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 442: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 443: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 444: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 445: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 446: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 447: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 448: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 449: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 450: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 451: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 452: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 453: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 454: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 455: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 456: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 457: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 458: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 459: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 460: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 461: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 462: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 463: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 464: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 465: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 466: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 467: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 468: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 469: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 470: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 471: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 472: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 473: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 474: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 475: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 476: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 477: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 478: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 479: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 480: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 481: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 482: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 483: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 484: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 485: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 486: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 487: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 488: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 489: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 490: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 491: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 492: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 493: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 494: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 495: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 496: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 497: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 498: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 499: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 500: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 501: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 502: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 503: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 504: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 505: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 506: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 507: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 508: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 509: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 510: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] Part 511: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=29 ] 
[09:35:16,898][INFO][sys-#265][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], err=null, rebalanced=true, wasRebalanced=false]
[09:35:16,898][INFO][sys-#265][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, addrs=ArrayList [0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], sockAddrs=HashSet [MSI/192.168.1.201:47500, /[0:0:0:0:0:0:0:1]:47500, /127.0.0.1:47500], discPort=47500, order=2, intOrder=2, lastExchangeTime=1717464916837, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1]]
[09:35:16,898][INFO][sys-#265][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (2 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (1006 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (2 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (26 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Validate partitions states" (7 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (4 ms), stage="Full message sending" (0 ms), stage="Exchange done" (0 ms), stage="Total time" (1047 ms), Discovery lag=18938 ms, Latest started node id=b003b5b3-8c19-4966-b469-85e6952d3d25]
[09:35:16,899][INFO][sys-#265][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], stage="Affinity change by custom message [grp=my_cache]" (1 ms) (parent=Determine exchange type), stage="Affinity change by custom message [grp=ignite-sys-cache]" (0 ms) (parent=Determine exchange type)]
[09:35:16,900][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=8, minorTopVer=1], force=false, evt=DISCOVERY_CUSTOM_EVT, node=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:36:14,987][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:17:00.113]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=8, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0.13%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=307MB, free=69.98%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:36:14,988][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=24, reusePages=731]
[09:36:53,624][WARNING][tcp-disco-msg-worker-[b003b5b3 192.168.1.133:47500 crd]-#2-#69][TcpDiscoverySpi] Timed out waiting for message delivery receipt (most probably, the reason is in long GC pauses on remote node; consider tuning GC and increasing 'ackTimeout' configuration property). Will retry to send message with increased timeout [currentTimeout=9647, rmtAddr=/192.168.1.133:47500, rmtPort=47500]
[09:36:53,626][WARNING][tcp-disco-msg-worker-[b003b5b3 192.168.1.133:47500 crd]-#2-#69][TcpDiscoverySpi] Failed to send message to next node [msg=TcpDiscoveryMetricsUpdateMessage [super=TcpDiscoveryAbstractMessage [sndNodeId=null, id=f0f94d0ef81-a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, verifierNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, topVer=0, pendingIdx=0, failedNodes=null, isClient=false]], next=TcpDiscoveryNode [id=b003b5b3-8c19-4966-b469-85e6952d3d25, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=8, intOrder=5, lastExchangeTime=1717464899841, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], errMsg=Failed to send message to next node [msg=TcpDiscoveryMetricsUpdateMessage [super=TcpDiscoveryAbstractMessage [sndNodeId=null, id=f0f94d0ef81-a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, verifierNodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, topVer=0, pendingIdx=0, failedNodes=null, isClient=false]], next=ClusterNode [id=b003b5b3-8c19-4966-b469-85e6952d3d25, order=8, addr=[0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133]]]]
[09:36:53,628][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: b003b5b3-8c19-4966-b469-85e6952d3d25
[09:36:53,628][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:36:53,628][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:36:53,628][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:36:53,628][WARNING][disco-event-worker-#75][GridDiscoveryManager] Node FAILED: TcpDiscoveryNode [id=b003b5b3-8c19-4966-b469-85e6952d3d25, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=8, intOrder=5, lastExchangeTime=1717464899841, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:36:53,630][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=9, locNode=a84ef531, servers=1, clients=0, state=ACTIVE, CPUs=16, offheap=3.2GB, heap=1.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:36:53,630][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=1, online=1, offline=0]
[09:36:53,640][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], crd=true, evt=NODE_FAILED, evtNode=b003b5b3-8c19-4966-b469-85e6952d3d25, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:36:53,642][INFO][sys-#286][IgniteTxManager] Checking optimistic transaction state on remote nodes [tx=GridDhtTxLocal [nearNodeId=b003b5b3-8c19-4966-b469-85e6952d3d25, nearFutId=f68f2e0ef81-eb18df5f-ac5f-4b85-8cea-6b81f1916b3a, nearMiniId=1, nearFinFutId=null, nearFinMiniId=0, nearXidVer=GridCacheVersion [topVer=328943904, order=1717464920651, nodeOrder=8, dataCenterId=0], lb=null, super=GridDhtTxLocalAdapter [nearOnOriginatingNode=false, nearNodes=KeySetView [], dhtNodes=KeySetView [], explicitLock=false, super=IgniteTxLocalAdapter [doneFlag=0, completedBase=null, commitErr=null, depEnabled=false, txState=IgniteTxImplicitSingleStateImpl [init=true, recovery=false, useMvccCaching=false], syncMode=null, super=IgniteTxAdapter [xidVer=GridCacheVersion [topVer=328943904, order=1717464920652, nodeOrder=2, dataCenterId=0], writeVer=GridCacheVersion [topVer=328943904, order=1717464920653, nodeOrder=2, dataCenterId=0], implicit=true, loc=true, threadId=118, startTime=1717465013185, startTimeNanos=-1, nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, needRetVal=false, isolation=READ_COMMITTED, concurrency=OPTIMISTIC, timeout=0, sysInvalidate=false, internal=false, sys=false, plc=2, commitVer=null, finalizing=RECOVERY_FINISH, invalidParts=null, state=PREPARED, timedOut=false, topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], subjId=null, taskNameHash=0, storeEnabled=true, mvccSnapshot=null, incSnpId=null, skipCompletedVers=false, parentTx=null, duration=439ms, onePhaseCommit=true], size=1]]], fut=GridCacheTxRecoveryFuture [trackable=true, futId=57f94d0ef81-e49c5930-9691-4a1b-961a-41b0579ce9f7, tx=GridDhtTxLocal [nearNodeId=b003b5b3-8c19-4966-b469-85e6952d3d25, nearFutId=f68f2e0ef81-eb18df5f-ac5f-4b85-8cea-6b81f1916b3a, nearMiniId=1, nearFinFutId=null, nearFinMiniId=0, nearXidVer=GridCacheVersion [topVer=328943904, order=1717464920651, nodeOrder=8, dataCenterId=0], lb=null, super=GridDhtTxLocalAdapter [nearOnOriginatingNode=false, nearNodes=KeySetView [], dhtNodes=KeySetView [], explicitLock=false, super=IgniteTxLocalAdapter [doneFlag=0, completedBase=null, commitErr=null, depEnabled=false, txState=IgniteTxImplicitSingleStateImpl [init=true, recovery=false, useMvccCaching=false], syncMode=null, super=IgniteTxAdapter [xidVer=GridCacheVersion [topVer=328943904, order=1717464920652, nodeOrder=2, dataCenterId=0], writeVer=GridCacheVersion [topVer=328943904, order=1717464920653, nodeOrder=2, dataCenterId=0], implicit=true, loc=true, threadId=118, startTime=1717465013185, startTimeNanos=-1, nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, needRetVal=false, isolation=READ_COMMITTED, concurrency=OPTIMISTIC, timeout=0, sysInvalidate=false, internal=false, sys=false, plc=2, commitVer=null, finalizing=RECOVERY_FINISH, invalidParts=null, state=PREPARED, timedOut=false, topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], subjId=null, taskNameHash=0, storeEnabled=true, mvccSnapshot=null, incSnpId=null, skipCompletedVers=false, parentTx=null, duration=455ms, onePhaseCommit=true], size=1]]], failedNodeIds=SingletonSet [b003b5b3-8c19-4966-b469-85e6952d3d25], nearTxCheck=false, innerFuts=EmptyList [], super=GridCompoundIdentityFuture [super=GridCompoundFuture [rdc=Bool reducer: true, initFlag=0, lsnrCalls=0, size=0, done=false, cancelled=false, err=null, futs=EmptyList []]]]]
[09:36:53,642][INFO][sys-#286][IgniteTxManager] Finishing prepared transaction [commit=true, tx=GridDhtTxLocal [nearNodeId=b003b5b3-8c19-4966-b469-85e6952d3d25, nearFutId=f68f2e0ef81-eb18df5f-ac5f-4b85-8cea-6b81f1916b3a, nearMiniId=1, nearFinFutId=null, nearFinMiniId=0, nearXidVer=GridCacheVersion [topVer=328943904, order=1717464920651, nodeOrder=8, dataCenterId=0], lb=null, super=GridDhtTxLocalAdapter [nearOnOriginatingNode=false, nearNodes=KeySetView [], dhtNodes=KeySetView [], explicitLock=false, super=IgniteTxLocalAdapter [doneFlag=0, completedBase=null, commitErr=null, depEnabled=false, txState=IgniteTxImplicitSingleStateImpl [init=true, recovery=false, useMvccCaching=false], syncMode=null, super=IgniteTxAdapter [xidVer=GridCacheVersion [topVer=328943904, order=1717464920652, nodeOrder=2, dataCenterId=0], writeVer=GridCacheVersion [topVer=328943904, order=1717464920653, nodeOrder=2, dataCenterId=0], implicit=true, loc=true, threadId=118, startTime=1717465013185, startTimeNanos=-1, nodeId=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, needRetVal=false, isolation=READ_COMMITTED, concurrency=OPTIMISTIC, timeout=0, sysInvalidate=false, internal=false, sys=false, plc=2, commitVer=null, finalizing=RECOVERY_FINISH, invalidParts=null, state=PREPARED, timedOut=false, topVer=AffinityTopologyVersion [topVer=8, minorTopVer=1], subjId=null, taskNameHash=0, storeEnabled=true, mvccSnapshot=null, incSnpId=null, skipCompletedVers=false, parentTx=null, duration=455ms, onePhaseCommit=true], size=1]]]]
[09:36:53,645][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], waitTime=3ms, futInfo=NA, mode=DISTRIBUTED]
[09:36:53,645][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=9, minorTopVer=0]]]]
[09:36:53,645][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:36:53,646][INFO][sys-#286][IgniteTxManager] TxRecovery Status and Timings [txs=1, stage="Started" (0 ms), stage="Initialized" (13 ms), stage="Finished" (0 ms), stage="Total time" (13 ms)]
[09:36:53,648][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=9, minorTopVer=0]]
[09:36:53,648][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=9, minorTopVer=0]]
[09:36:53,663][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], err=null, rebalanced=true, wasRebalanced=true]
[09:36:53,665][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], evt=NODE_FAILED, evtNode=TcpDiscoveryNode [id=b003b5b3-8c19-4966-b469-85e6952d3d25, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=8, intOrder=5, lastExchangeTime=1717464899841, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=9, minorTopVer=0]]
[09:36:53,665][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (4 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Finalize update counters" (2 ms), stage="Waiting for all single messages" (0 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (8 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (1 ms), stage="Full message preparing" (3 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Detect lost partitions" (1 ms), stage="Exchange done" (1 ms), stage="Total time" (21 ms)]
[09:36:53,665][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], stage="Affinity recalculation (partitions availability) [grp=my_cache]" (5 ms) (parent=Affinity recalculation (crd)), stage="Affinity recalculation (partitions availability) [grp=ignite-sys-cache]" (5 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (enforced) [grp=my_cache]" (3 ms) (parent=Affinity recalculation (crd))]
[09:36:53,666][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=9, minorTopVer=0], crd=true]
[09:36:53,668][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=9, minorTopVer=0], force=false, evt=NODE_FAILED, node=b003b5b3-8c19-4966-b469-85e6952d3d25]
[09:36:54,299][INFO][tcp-disco-sock-reader-[b003b5b3 192.168.1.133:61666]-#20-#274][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61666, rmtPort=61666, rmtNodeId=b003b5b3-8c19-4966-b469-85e6952d3d25]
[09:37:14,854][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61683]
[09:37:14,854][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61683]
[09:37:14,854][INFO][tcp-disco-sock-reader-[]-#21-#299][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61683, rmtPort=61683]
[09:37:14,855][INFO][tcp-disco-sock-reader-[753b0365 192.168.1.133:61683]-#21-#299][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=753b0365-c095-4061-b4c7-327ed1891d13, rmtAddr=/192.168.1.133:61683]
[09:37:14,953][INFO][tcp-disco-sock-reader-[753b0365 192.168.1.133:61683]-#21-#299][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61683, rmtPort=61683, rmtNodeId=753b0365-c095-4061-b4c7-327ed1891d13]
[09:37:14,954][INFO][tcp-disco-msg-worker-[crd]-#2-#69][GridEncryptionManager] Joining node doesn't have stored group keys [node=753b0365-c095-4061-b4c7-327ed1891d13]
[09:37:14,957][INFO][tcp-disco-msg-worker-[crd]-#2-#69][TcpDiscoverySpi] New next node [newNext=TcpDiscoveryNode [id=753b0365-c095-4061-b4c7-327ed1891d13, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=0, intOrder=6, lastExchangeTime=1717465034881, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]]
[09:37:15,005][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:18:00.131]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=9, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=321MB, free=68.62%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=2, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:37:15,005][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=34, reusePages=721]
[09:37:16,759][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61684]
[09:37:16,759][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61684]
[09:37:16,759][INFO][tcp-disco-sock-reader-[]-#22-#300][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61684, rmtPort=61684]
[09:37:16,759][INFO][tcp-disco-sock-reader-[753b0365 192.168.1.133:61684]-#22-#300][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=753b0365-c095-4061-b4c7-327ed1891d13, rmtAddr=/192.168.1.133:61684]
[09:37:16,869][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: 753b0365-c095-4061-b4c7-327ed1891d13
[09:37:16,869][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:37:16,869][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:37:16,869][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:37:16,869][INFO][disco-event-worker-#75][GridDiscoveryManager] Added new node to topology: TcpDiscoveryNode [id=753b0365-c095-4061-b4c7-327ed1891d13, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=10, intOrder=6, lastExchangeTime=1717465034881, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:37:16,870][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=10, locNode=a84ef531, servers=2, clients=0, state=ACTIVE, CPUs=24, offheap=6.4GB, heap=5.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42], TcpDiscoveryNode [id=753b0365-c095-4061-b4c7-327ed1891d13, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:37:16,870][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=2, online=2, offline=0]
[09:37:16,871][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], crd=true, evt=NODE_JOINED, evtNode=753b0365-c095-4061-b4c7-327ed1891d13, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:37:16,871][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:37:16,871][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0]]]]
[09:37:16,871][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:37:16,871][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], crd=true]
[09:37:17,277][INFO][grid-nio-worker-tcp-comm-0-#39%TcpCommunicationSpi%][TcpCommunicationSpi] Accepted incoming communication connection [locAddr=/192.168.1.201:47100, rmtAddr=/192.168.1.133:61685]
[09:37:17,340][INFO][sys-#296][GridDhtPartitionsExchangeFuture] Coordinator received single message [ver=AffinityTopologyVersion [topVer=10, minorTopVer=0], node=753b0365-c095-4061-b4c7-327ed1891d13, allReceived=true]
[09:37:17,341][INFO][sys-#296][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=10, minorTopVer=0]]
[09:37:17,341][INFO][sys-#296][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=10, minorTopVer=0]]
[09:37:17,361][INFO][sys-#296][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], err=null, rebalanced=false, wasRebalanced=true]
[09:37:17,363][INFO][sys-#296][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], evt=NODE_JOINED, evtNode=TcpDiscoveryNode [id=753b0365-c095-4061-b4c7-327ed1891d13, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=10, intOrder=6, lastExchangeTime=1717465034881, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=false, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0]]
[09:37:17,364][INFO][sys-#296][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (470 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (9 ms), stage="Collect update counters and create affinity messages" (1 ms), stage="Assign partitions states" (1 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (1 ms), stage="Full message preparing" (4 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Exchange done" (2 ms), stage="Total time" (489 ms), Discovery lag=18219 ms, Latest started node id=753b0365-c095-4061-b4c7-327ed1891d13]
[09:37:17,364][INFO][sys-#296][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], stage="Affinity initialization (node join) [grp=my_cache, crd=true]" (8 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (node join) [grp=ignite-sys-cache, crd=true]" (2 ms) (parent=Affinity recalculation (crd))]
[09:37:17,365][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=10, minorTopVer=0], force=false, evt=NODE_JOINED, node=753b0365-c095-4061-b4c7-327ed1891d13]
[09:37:17,891][INFO][rebalance-striped-#303][GridDhtPartitionSupplier] Finished supplying rebalancing [grp=ignite-sys-cache, demander=753b0365-c095-4061-b4c7-327ed1891d13, topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0]]
[09:37:17,934][INFO][rebalance-striped-#303][GridDhtPartitionSupplier] Finished supplying rebalancing [grp=my_cache, demander=753b0365-c095-4061-b4c7-327ed1891d13, topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0]]
[09:37:22,451][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, customEvt=CacheAffinityChangeMessage [id=aef94d0ef81-e49c5930-9691-4a1b-961a-41b0579ce9f7, topVer=AffinityTopologyVersion [topVer=10, minorTopVer=0], exchId=null, partsMsg=null, exchangeNeeded=true, stopProc=false], allowMerge=false, exchangeFreeSwitch=false]
[09:37:22,452][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:37:22,603][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=10, minorTopVer=1]]]]
[09:37:22,604][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:37:22,605][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], crd=true]
[09:37:22,619][INFO][sys-#286][GridDhtPartitionsExchangeFuture] Coordinator received single message [ver=AffinityTopologyVersion [topVer=10, minorTopVer=1], node=753b0365-c095-4061-b4c7-327ed1891d13, allReceived=true]
[09:37:22,619][INFO][sys-#286][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=10, minorTopVer=1]]
[09:37:22,627][WARNING][sys-#288][GridDhtPartitionsExchangeFuture] Partition states validation has failed for group: my_cache, msg: Partitions cache sizes are inconsistent for Part 0: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=1 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 1: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=1 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 2: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 3: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 4: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 5: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 6: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 7: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 8: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 9: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 10: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 11: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 12: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 13: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 14: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 15: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 16: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 17: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 18: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 19: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 20: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 21: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 22: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 23: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 24: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 25: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 26: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 27: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 28: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 29: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 30: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 31: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 32: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 33: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 34: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 35: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 36: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 37: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 38: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 39: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 40: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 41: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 42: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 43: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 44: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 45: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 46: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 47: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 48: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 49: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 50: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 51: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 52: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 53: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 54: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 55: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 56: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 57: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 58: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 59: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 60: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 61: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 62: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 63: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 64: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 65: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 66: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 67: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 68: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 69: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 70: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 71: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 72: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 73: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 74: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 75: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 76: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 77: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 78: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 79: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 80: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 81: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 82: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 83: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 84: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 85: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 86: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 87: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 88: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 89: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 90: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 91: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 92: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 93: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 94: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 95: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 96: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 97: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 98: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 99: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 100: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 101: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 102: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 103: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 104: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 105: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 106: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 107: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 108: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 109: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 110: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 111: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 112: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 113: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 114: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 115: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 116: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 117: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 118: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 119: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 120: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 121: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 122: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 123: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 124: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 125: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 126: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 127: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 128: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 129: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 130: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 131: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 132: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 133: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 134: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 135: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 136: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 137: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 138: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 139: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 140: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 141: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 142: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 143: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 144: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 145: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 146: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 147: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 148: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 149: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 150: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 151: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 152: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 153: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 154: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 155: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 156: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 157: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 158: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 159: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 160: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 161: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 162: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 163: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 164: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 165: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 166: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 167: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 168: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 169: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 170: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 171: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 172: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 173: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 174: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 175: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 176: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 177: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 178: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 179: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 180: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 181: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 182: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 183: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 184: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 185: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 186: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 187: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 188: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 189: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 190: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 191: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 192: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 193: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 194: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 195: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 196: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 197: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 198: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 199: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 200: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 201: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 202: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 203: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 204: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 205: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 206: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 207: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 208: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 209: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 210: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 211: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 212: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 213: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 214: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 215: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 216: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 217: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 218: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 219: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 220: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 221: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 222: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 223: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 224: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 225: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 226: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 227: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 228: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 229: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 230: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 231: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 232: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 233: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 234: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 235: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 236: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 237: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 238: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 239: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 240: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 241: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 242: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 243: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 244: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 245: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 246: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 247: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 248: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 249: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 250: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 251: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 252: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 253: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 254: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 255: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 256: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 257: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 258: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 259: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 260: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 261: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 262: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 263: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 264: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 265: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 266: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 267: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 268: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 269: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 270: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 271: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 272: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 273: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 274: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=4 ] Part 275: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 276: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 277: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 278: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 279: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 280: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 281: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 282: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 283: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 284: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 285: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 286: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 287: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 288: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 289: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 290: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 291: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 292: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 293: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 294: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 295: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 296: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 297: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 298: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 299: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 300: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 301: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 302: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 303: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 304: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 305: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 306: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 307: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 308: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 309: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 310: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 311: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 312: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 313: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 314: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 315: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 316: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 317: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 318: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 319: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 320: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 321: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 322: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 323: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 324: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 325: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 326: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 327: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 328: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 329: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 330: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 331: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 332: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 333: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 334: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 335: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 336: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 337: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 338: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 339: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 340: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 341: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 342: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 343: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 344: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 345: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 346: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 347: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 348: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 349: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 350: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 351: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 352: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 353: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 354: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 355: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 356: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 357: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 358: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 359: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 360: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 361: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 362: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 363: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 364: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 365: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 366: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 367: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 368: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 369: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 370: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 371: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 372: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 373: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 374: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 375: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 376: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 377: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 378: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 379: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 380: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 381: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 382: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 383: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 384: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 385: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 386: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 387: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 388: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 389: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 390: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 391: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 392: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 393: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 394: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 395: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 396: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 397: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 398: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 399: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 400: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 401: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 402: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 403: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 404: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 405: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 406: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 407: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 408: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 409: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 410: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 411: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 412: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 413: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 414: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 415: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 416: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 417: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 418: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 419: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 420: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 421: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 422: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 423: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 424: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 425: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 426: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 427: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 428: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 429: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 430: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 431: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 432: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 433: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 434: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 435: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 436: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 437: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 438: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 439: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 440: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 441: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 442: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 443: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 444: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 445: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 446: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 447: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 448: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 449: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 450: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 451: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 452: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 453: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 454: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 455: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 456: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 457: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 458: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 459: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 460: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 461: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 462: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 463: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 464: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 465: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 466: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 467: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 468: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 469: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 470: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 471: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 472: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 473: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 474: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 475: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 476: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 477: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 478: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 479: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 480: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 481: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 482: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 483: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 484: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 485: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 486: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 487: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 488: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 489: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 490: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 491: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 492: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 493: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 494: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 495: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 496: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 497: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 498: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 499: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 500: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 501: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 502: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 503: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 504: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 505: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 506: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 507: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 508: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 509: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 510: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] Part 511: [0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500=0 0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500=3 ] 
[09:37:22,633][INFO][sys-#286][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], err=null, rebalanced=true, wasRebalanced=false]
[09:37:22,634][INFO][sys-#286][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, addrs=ArrayList [0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], sockAddrs=HashSet [MSI/192.168.1.201:47500, /[0:0:0:0:0:0:0:1]:47500, /127.0.0.1:47500], discPort=47500, order=2, intOrder=2, lastExchangeTime=1717465042560, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=10, minorTopVer=1]]
[09:37:22,634][INFO][sys-#286][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (150 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (1 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (13 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Validate partitions states" (8 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (3 ms), stage="Full message sending" (0 ms), stage="Exchange done" (0 ms), stage="Total time" (175 ms), Discovery lag=18013 ms, Latest started node id=753b0365-c095-4061-b4c7-327ed1891d13]
[09:37:22,634][INFO][sys-#286][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=10, minorTopVer=1], stage="Affinity change by custom message [grp=my_cache]" (0 ms) (parent=Determine exchange type), stage="Affinity change by custom message [grp=ignite-sys-cache]" (0 ms) (parent=Determine exchange type)]
[09:37:22,635][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=10, minorTopVer=1], force=false, evt=DISCOVERY_CUSTOM_EVT, node=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1]
[09:38:15,018][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:19:00.144]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=10, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=340MB, free=66.76%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:38:15,018][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=31, reusePages=724]
[09:39:15,027][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:20:00.153]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=10, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0.03%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=361MB, free=64.71%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:39:15,027][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=80, reusePages=674]
[09:40:15,037][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:21:00.162]
    ^-- Cluster [hosts=2, CPUs=24, servers=2, clients=0, topVer=10, minorTopVer=1]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=370MB, free=63.83%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:40:15,037][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:41:08,878][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: 753b0365-c095-4061-b4c7-327ed1891d13
[09:41:08,878][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:41:08,878][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:41:08,878][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:41:08,879][INFO][disco-event-worker-#75][GridDiscoveryManager] Node left topology: TcpDiscoveryNode [id=753b0365-c095-4061-b4c7-327ed1891d13, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=10, intOrder=6, lastExchangeTime=1717465034881, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:41:08,881][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=11, locNode=a84ef531, servers=1, clients=0, state=ACTIVE, CPUs=16, offheap=3.2GB, heap=1.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:41:08,881][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=1, online=1, offline=0]
[09:41:08,893][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], crd=true, evt=NODE_LEFT, evtNode=753b0365-c095-4061-b4c7-327ed1891d13, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:41:08,894][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:41:08,894][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=11, minorTopVer=0]]]]
[09:41:08,894][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:41:08,897][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=11, minorTopVer=0]]
[09:41:08,897][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=11, minorTopVer=0]]
[09:41:08,911][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], err=null, rebalanced=true, wasRebalanced=true]
[09:41:08,913][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], evt=NODE_LEFT, evtNode=TcpDiscoveryNode [id=753b0365-c095-4061-b4c7-327ed1891d13, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=10, intOrder=6, lastExchangeTime=1717465034881, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=11, minorTopVer=0]]
[09:41:08,913][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Finalize update counters" (2 ms), stage="Waiting for all single messages" (0 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (7 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (1 ms), stage="Full message preparing" (3 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Detect lost partitions" (1 ms), stage="Exchange done" (1 ms), stage="Total time" (16 ms)]
[09:41:08,914][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], stage="Affinity recalculation (partitions availability) [grp=ignite-sys-cache]" (4 ms) (parent=Affinity recalculation (crd)), stage="Affinity recalculation (partitions availability) [grp=my_cache]" (3 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (enforced) [grp=my_cache]" (2 ms) (parent=Affinity recalculation (crd))]
[09:41:08,914][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=11, minorTopVer=0], crd=true]
[09:41:08,916][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=11, minorTopVer=0], force=false, evt=NODE_LEFT, node=753b0365-c095-4061-b4c7-327ed1891d13]
[09:41:09,448][INFO][tcp-disco-sock-reader-[753b0365 192.168.1.133:61684]-#22-#300][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61684, rmtPort=61684, rmtNodeId=753b0365-c095-4061-b4c7-327ed1891d13]
[09:41:15,045][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:22:00.171]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=11, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0.37%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=378MB, free=63.05%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=2, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:41:15,045][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:41:55,542][WARNING][tcp-disco-ip-finder-cleaner-#7-#74][TcpDiscoverySpi] Failed to ping node [nodeId=null]. Reached the timeout 10000ms. Cause: Connection refused: getsockopt
[09:41:55,542][WARNING][tcp-disco-ip-finder-cleaner-#7-#74][TcpDiscoverySpi] Failed to ping node [nodeId=null]. Was unable to open the socket at all. Cause: no such interface lo0
[09:42:15,047][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:23:00.172]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=11, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=383MB, free=62.56%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:42:15,047][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:43:15,049][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:24:00.174]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=11, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=386MB, free=62.27%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:43:15,049][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:44:15,056][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:25:00.179]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=11, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.09%, GC=0%]
    ^-- Heap [used=389MB, free=61.97%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:44:15,056][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:44:54,223][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61821]
[09:44:54,223][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61821]
[09:44:54,223][INFO][tcp-disco-sock-reader-[]-#23-#363][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61821, rmtPort=61821]
[09:44:54,224][INFO][tcp-disco-sock-reader-[548f0c80 192.168.1.133:61821]-#23-#363][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=548f0c80-14da-429d-a61b-1a0e6656854a, rmtAddr=/192.168.1.133:61821]
[09:44:54,341][INFO][tcp-disco-sock-reader-[548f0c80 192.168.1.133:61821]-#23-#363][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61821, rmtPort=61821, rmtNodeId=548f0c80-14da-429d-a61b-1a0e6656854a]
[09:44:54,342][INFO][tcp-disco-msg-worker-[crd]-#2-#69][GridEncryptionManager] Joining node doesn't have stored group keys [node=548f0c80-14da-429d-a61b-1a0e6656854a]
[09:44:54,345][INFO][tcp-disco-msg-worker-[crd]-#2-#69][TcpDiscoverySpi] New next node [newNext=TcpDiscoveryNode [id=548f0c80-14da-429d-a61b-1a0e6656854a, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=0, intOrder=7, lastExchangeTime=1717465494248, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]]
[09:44:54,848][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery accepted incoming connection [rmtAddr=/192.168.1.133, rmtPort=61822]
[09:44:54,848][INFO][tcp-disco-srvr-[:47500]-#3-#70][TcpDiscoverySpi] TCP discovery spawning a new thread for connection [rmtAddr=/192.168.1.133, rmtPort=61822]
[09:44:54,849][INFO][tcp-disco-sock-reader-[]-#24-#364][TcpDiscoverySpi] Started serving remote node connection [rmtAddr=/192.168.1.133:61822, rmtPort=61822]
[09:44:54,855][INFO][tcp-disco-sock-reader-[548f0c80 192.168.1.133:61822]-#24-#364][TcpDiscoverySpi] Initialized connection with remote server node [nodeId=548f0c80-14da-429d-a61b-1a0e6656854a, rmtAddr=/192.168.1.133:61822]
[09:44:54,945][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: 548f0c80-14da-429d-a61b-1a0e6656854a
[09:44:54,945][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:44:54,945][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:44:54,945][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:44:54,946][INFO][disco-event-worker-#75][GridDiscoveryManager] Added new node to topology: TcpDiscoveryNode [id=548f0c80-14da-429d-a61b-1a0e6656854a, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=12, intOrder=7, lastExchangeTime=1717465494248, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:44:54,947][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=12, locNode=a84ef531, servers=2, clients=0, state=ACTIVE, CPUs=24, offheap=6.4GB, heap=5.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42], TcpDiscoveryNode [id=548f0c80-14da-429d-a61b-1a0e6656854a, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:44:54,948][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=2, online=2, offline=0]
[09:44:54,948][INFO][exchange-worker-#77][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=12, minorTopVer=0], crd=true, evt=NODE_JOINED, evtNode=548f0c80-14da-429d-a61b-1a0e6656854a, customEvt=null, allowMerge=true, exchangeFreeSwitch=false]
[09:44:54,949][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=12, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[09:44:54,950][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=12, minorTopVer=0]]]]
[09:44:54,950][INFO][exchange-worker-#77][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=12, minorTopVer=0], waitTime=0ms, futInfo=NA, mode=LOCAL]
[09:44:54,950][INFO][exchange-worker-#77][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=12, minorTopVer=0], crd=true]
[09:44:55,079][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: 548f0c80-14da-429d-a61b-1a0e6656854a
[09:44:55,079][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Started state transition: activate cluster
[09:44:55,079][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Received state change finish message: ACTIVE
[09:44:55,079][INFO][disco-notifier-worker-#68][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[09:44:55,079][INFO][disco-event-worker-#75][GridDiscoveryManager] Node left topology: TcpDiscoveryNode [id=548f0c80-14da-429d-a61b-1a0e6656854a, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=12, intOrder=7, lastExchangeTime=1717465494248, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false]
[09:44:55,080][INFO][disco-event-worker-#75][GridDiscoveryManager] Topology snapshot [ver=13, locNode=a84ef531, servers=1, clients=0, state=ACTIVE, CPUs=16, offheap=3.2GB, heap=1.0GB, aliveNodes=[TcpDiscoveryNode [id=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, consistentId=0:0:0:0:0:0:0:1,127.0.0.1,192.168.1.201:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[09:44:55,080][INFO][disco-event-worker-#75][GridDiscoveryManager]   ^-- Baseline [id=0, size=1, online=1, offline=0]
[09:44:55,083][INFO][sys-#368][GridDhtPartitionsExchangeFuture] Coordinator received all messages, try merge [ver=AffinityTopologyVersion [topVer=12, minorTopVer=0]]
[09:44:55,083][INFO][sys-#368][GridCachePartitionExchangeManager] Merge exchange future [curFut=AffinityTopologyVersion [topVer=12, minorTopVer=0], mergedFut=AffinityTopologyVersion [topVer=13, minorTopVer=0], evt=NODE_LEFT, evtNode=548f0c80-14da-429d-a61b-1a0e6656854a, evtNodeClient=false]
[09:44:55,083][INFO][sys-#368][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=12, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=13, minorTopVer=0]]
[09:44:55,087][INFO][sys-#368][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=12, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=13, minorTopVer=0], err=null, rebalanced=true, wasRebalanced=true]
[09:44:55,087][INFO][sys-#368][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=a84ef531-529f-41b0-bf7b-ad5fd9d5feb1, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=12, minorTopVer=0], evt=NODE_JOINED, evtNode=TcpDiscoveryNode [id=548f0c80-14da-429d-a61b-1a0e6656854a, consistentId=0:0:0:0:0:0:0:1%lo0,127.0.0.1,192.168.1.133:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo0, 127.0.0.1, 192.168.1.133], sockAddrs=HashSet [/192.168.1.133:47500, /127.0.0.1:47500, 0:0:0:0:0:0:0:1%lo0/<unresolved>:47500], discPort=47500, order=12, intOrder=7, lastExchangeTime=1717465494248, loc=false, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=13, minorTopVer=0]]
[09:44:55,087][INFO][sys-#368][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=12, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=13, minorTopVer=0], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (0 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (133 ms), stage="Exchanges merge" (0 ms), stage="Affinity recalculation (crd)" (2 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (0 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (0 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Detect lost partitions" (0 ms), stage="Exchange done" (0 ms), stage="Total time" (135 ms)]
[09:44:55,087][INFO][sys-#368][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=12, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=13, minorTopVer=0], stage="Affinity recalculation (partitions availability) [grp=my_cache]" (1 ms) (parent=Affinity recalculation (crd)), stage="Affinity recalculation (partitions availability) [grp=ignite-sys-cache]" (1 ms) (parent=Affinity recalculation (crd)), stage="Affinity initialization (enforced) [grp=my_cache]" (0 ms) (parent=Affinity recalculation (crd))]
[09:44:55,088][INFO][exchange-worker-#77][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=13, minorTopVer=0], force=false, evt=NODE_JOINED, node=548f0c80-14da-429d-a61b-1a0e6656854a]
[09:44:55,529][INFO][tcp-disco-sock-reader-[548f0c80 192.168.1.133:61822]-#24-#364][TcpDiscoverySpi] Finished serving remote node connection [rmtAddr=/192.168.1.133:61822, rmtPort=61822, rmtNodeId=548f0c80-14da-429d-a61b-1a0e6656854a]
[09:45:01,578][WARNING][tcp-disco-ip-finder-cleaner-#7-#74][TcpDiscoverySpi] Failed to ping node [nodeId=null]. Reached the timeout 10000ms. Cause: Connection refused: getsockopt
[09:45:01,579][WARNING][tcp-disco-ip-finder-cleaner-#7-#74][TcpDiscoverySpi] Failed to ping node [nodeId=null]. Was unable to open the socket at all. Cause: no such interface lo0
[09:45:15,064][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:26:00.188]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.09%, GC=0%]
    ^-- Heap [used=398MB, free=61.1%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=2, qSize=0]
    ^-- System thread pool [active=0, idle=16, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:45:15,064][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:46:15,073][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:27:00.198]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.08%, GC=0%]
    ^-- Heap [used=400MB, free=60.9%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:46:15,073][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:47:15,084][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:28:00.210]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.08%, GC=0%]
    ^-- Heap [used=403MB, free=60.61%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:47:15,084][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:48:15,095][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:29:00.220]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.08%, GC=0%]
    ^-- Heap [used=405MB, free=60.41%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:48:15,095][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:49:15,107][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:30:00.233]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.07%, GC=0%]
    ^-- Heap [used=407MB, free=60.22%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:49:15,107][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:50:15,114][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:31:00.239]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.07%, GC=0%]
    ^-- Heap [used=410MB, free=59.92%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:50:15,114][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:51:15,122][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:32:00.248]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.07%, GC=0%]
    ^-- Heap [used=413MB, free=59.63%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:51:15,122][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:52:15,141][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:33:00.266]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.07%, GC=0%]
    ^-- Heap [used=416MB, free=59.34%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:52:15,141][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:53:15,147][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:34:00.273]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.06%, GC=0%]
    ^-- Heap [used=419MB, free=59.04%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:53:15,147][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:54:15,155][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:35:00.281]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.06%, GC=0%]
    ^-- Heap [used=421MB, free=58.85%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:54:15,155][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:55:15,160][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:36:00.285]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.06%, GC=0%]
    ^-- Heap [used=423MB, free=58.65%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:55:15,160][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:56:15,171][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:37:00.296]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.06%, GC=0%]
    ^-- Heap [used=425MB, free=58.46%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:56:15,171][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:57:15,177][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:38:00.302]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.06%, GC=0%]
    ^-- Heap [used=428MB, free=58.17%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:57:15,178][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:58:15,187][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:39:00.313]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.05%, GC=0%]
    ^-- Heap [used=431MB, free=57.87%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:58:15,187][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[09:59:15,201][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:40:00.327]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.05%, GC=0%]
    ^-- Heap [used=434MB, free=57.58%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[09:59:15,201][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:00:15,203][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:41:00.329]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.05%, GC=0%]
    ^-- Heap [used=436MB, free=57.38%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:00:15,203][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:01:15,216][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:42:00.342]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.05%, GC=0%]
    ^-- Heap [used=439MB, free=57.09%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:01:15,216][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:02:15,230][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:43:00.356]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.05%, GC=0%]
    ^-- Heap [used=442MB, free=56.8%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:02:15,230][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:03:15,238][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:44:00.364]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.05%, GC=0%]
    ^-- Heap [used=445MB, free=56.51%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:03:15,238][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:04:15,247][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:45:00.373]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.05%, GC=0%]
    ^-- Heap [used=447MB, free=56.31%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:04:15,247][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:05:15,248][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:46:00.374]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.04%, GC=0%]
    ^-- Heap [used=450MB, free=56.02%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:05:15,248][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:06:15,250][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:47:00.376]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.04%, GC=0%]
    ^-- Heap [used=453MB, free=55.72%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:06:15,250][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:07:15,264][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:48:00.390]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.04%, GC=0%]
    ^-- Heap [used=456MB, free=55.43%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:07:15,264][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:08:15,267][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:49:00.393]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.04%, GC=0%]
    ^-- Heap [used=458MB, free=55.24%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:08:15,267][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:09:15,290][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:50:00.416]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.04%, GC=0%]
    ^-- Heap [used=461MB, free=54.94%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:09:15,290][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:10:15,317][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:51:00.443]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.04%, GC=0%]
    ^-- Heap [used=464MB, free=54.65%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:10:15,317][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:11:15,326][INFO][grid-timeout-worker-#38][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=a84ef531, uptime=00:52:00.452]
    ^-- Cluster [hosts=1, CPUs=16, servers=1, clients=0, topVer=13, minorTopVer=0]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1, 127.0.0.1, 192.168.1.201], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=16, curLoad=0%, avgLoad=0.04%, GC=0%]
    ^-- Heap [used=466MB, free=54.45%, comm=1024MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=16, qSize=0]
[10:11:15,326][INFO][grid-timeout-worker-#38][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=91, reusePages=663]
[10:11:20,836][INFO][shutdown-hook][G] Invoking shutdown hook...
